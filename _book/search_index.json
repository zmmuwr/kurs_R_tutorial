[["index.html", "Kurs R - Tutorial Chapter 1 Wstęp", " Kurs R - Tutorial Agnieszka Strzałka 2021-08-26 Chapter 1 Wstęp Książka jest dodatkiem do kursu R i ma stanowić zbiór przykładów, które mogą zostać wykorzystane podczas pisania własnych skryptów R. Materiały będą na bieżąco aktualizowane tak aby wszystkie przedstawione przykłady były możliwe do odtworzenia. Większość przedstawionych przykładów będzie się opierać na funkcjach zawartych w pakietach tidyverse, które tworzą spójną całość obejmującą wczytanie i analizę danych oraz ich wizualizację. Chociaż wiele z przedstawionych zadań może być wykonane korzystając z podstawowych funkcji R uważam, że nauczenie się od razu korzystania z pakietów tidyverse za bardziej korzystne gdyż zawarte w nich funkcje są często łatwiejsze i bardziej intuicyjne w stosowaniu, szczególnie gdy ktoś nie ma dużego doświadczenia w programowaniu ;) ## ## R is the lingua franca of statistical research. Work in all other languages ## should be discouraged. ## -- Jan de Leeuw (as quoted by Matt Pocernich on R-help) ## JSM 2003, San Francisco (August 2003) "],["skąd-ściągnąć-r.html", "Chapter 2 Skąd ściągnąć R 2.1 Pomoc 2.2 Packages 2.3 R Studio", " Chapter 2 Skąd ściągnąć R Postawowe środowisko R najlepiej ściągnąć bezpośrednio ze strony R project Polecam również ściągnąć R Studio, które bardzo ułatwia pracę z R Podstawowe pakiety zostaną zainstalowane razem z R, kolejne można pobrać bezpośrednio przez R Studio (zakładka Packages), bardziej bioinformatyczne pakiety znajdują się na stronie bioconductor, wiele pakietów można też pobrac bezpośrednio ze strony Github korzystając z pakietu devtools. ## ## Friends don&#39;t let friends use Excel for statistics! ## -- Jonathan D. Cryer (about problems with using Microsoft Excel for ## statistics) ## JSM 2001, Atlanta (August 2001) 2.1 Pomoc Pomoc do funkcji można otworzyć bezpośrednio w R wpisując: ? nazwa_funkcji albo naciskając F1 podczas wpisywania nazwy funkcji, jednak opisy często są dość enigmatyczne i zakładają już pewne zrozumienie tematu Odpowiedzi na konkretne pytania najlepiej szukać w internecie wpisując po prostu: “How do sth R,” najczęściej pojawiająca się strona to Stack Overflow Ciekawe pomysły i tutoriale pojawiają się też na stronie R-bloggers Interaktywny kurs R można też znaleźć na stronie datacamp, ale obecnie tylko pierwsze lekcje każdego kursu są darmowe Pomoc do ggplot2 Polecam też książkę Przemysława Biecka “Przewodnik po pakiecie R,” jedna z niewielu jakie są po polsku, pierwsze rozdziały można bezpłatnie pobrać ze strony autora Introduction to R for Biologists How to make any plot in ggplot2? Fundamentals of Data Visualization R Graphics Cookbook, 2nd edition No i oczywiście ja chętnie pomogę :) ## ## You need to get the hang of reading the online help. The information required ## is actually there in ?dotchart --- it&#39;s just tersely and obscurely expressed. A ## certain degree of optimism is required. You need to ***believe*** that the ## information is there; then ask yourself &quot;What could they possibly mean by what ## they have written that would tell me what I need to know?&quot;. ## -- Rolf Turner (on reading the help pages) ## R-help (June 2013) 2.2 Packages Żeby użyć funkcję z danego pakietu, który nie należy do podstawowych należy go najpierw zainstalować (Install w zakładce Packages), a potem załadować. (funkcje library(nazwa) albo require(nazwa)). Można też włączać pakiety w zakładce Packages. Dobrze jest ładować tylko te pakiety, które są faktycznie potrzebne - nie przeciążamy pamięci i niektóre nazwy funkcji mogą się powtarzać w różnych pakietach. Jeżeli ładowanie całego pakietu jest niepotrzebne albo prowadzi do konflktów można odwołać się do konkretnej funckji przy pomocy :: np. readxl::read_excel(). Każdy pakiet zawiera podstawowy opis funkcji, niektóre posiadają bardziej rozbudowane przykłady analiz jakie można przy ich pomocy wykonać - vignette. Jeżeli chcemy sprawdzić które pakiety zawierają winietki można to zrobić funkcją browseVignettes. 2.2.1 Lista pakietów, które pojawiają się w książce (uwaga może być niekompletna) Przed rozpoczęciem należy mieć zainstalowane następujące pakiety: ggplot2, tidyr, knitr, dplyr, readr, readxl oraz najlepiej posiadać najnowszą wersję R (4.1.0 - “Camp Pontanezen”) i R Studio (przynajmniej 1.4). Pozostałe pakiety można pobrać tylko jeśli będą potrzebne. Inne pakiety jakie pojawiają się to: w części dotyczącej wykresów: car, likert, gplots, VennDiagram, corrplot, hexbin, aplpack, GGally, ggthemes, ggthemr i w części dotyczącej statystyki i obróbki danych: car, MASS, nortest, modeest, moments, agricolae, drc, broom. 2.3 R Studio Jest to obecnie najpopularniejszy dostępny edytor R, pozwalający na tworzenie projektów, pisanie i zarządzanie skryptami, pozwalający na łatwy dostęp do historii wpisywanych komend i tworzonych wykresów. Został zintegrowany z wieloma przydatnymi pakietami np. knitr, który pozwala tworzenie raportów w języku markdown, latex, prezentacji multimedialnych itp. R Studio pozwala również na założenie projektu do konkretnego zadania, wszystkie pliki tworzone w trakcie pracy (wykresy, tabele, skrypty) zostaną umieszczone w folderze przypisanym do projektu. Jeżeli nasze dane wejściowe umieścimy w tym samym miejscu nie będzie konieczne podawanie całej ścieżki dostępu przy wczytywaniu pliku. Wykorzystanie projektów ułtwia uporządkowanie pracy. Każdy projekt można też poddać kontroli wersji przy pomocy Git i Github bezpośrednio z Rstudio. Więcej informacji na ten temat można znaleźć w Happy Git with R. Cały Tutorial to zbiór skryptów napisanych w markdown, które zostały połączone w książkę dzięki pakietowi R bookdown. Wszystkie przykłady można skopiować albo przepisać do własnych skryptów R. Trzeba jedynie pamiętać o wcześniejszym załadowaniu odpowiednich pakietów i ewentualnie danych. Samodzielne wpisywanie nazw funkcji przyśpiesza proces zapamiętywania, a korzystając z autouzpełniania trzeba tak naprawdę pamiętać 2-3 pierwsze litery :) "],["dane.html", "Chapter 3 Dane 3.1 Wczytanie danych 3.2 Zapisanie danych 3.3 Podstawowe typy danych w R", " Chapter 3 Dane 3.1 Wczytanie danych Dane najłatwiej wczytać z plików .txt lub .csv. Można również z plików .xlsx lub .xls ale często trwa to dłużej i może wymagać zainstalowanych innych pakietów/programów. W każdym przypadku niezbędne jest podanie ścieżki dostępu do pliku. Jeżeli znajduje się on folderze projektu to wystarczy jego nazwa. Dobrą praktyka jest przechowywanie danych w osobnym katalogu w obrębie projektu - wtedy ścieżka może wyglądać np. data/dane_1.txt. Jeżeli plik z danymi jest przechowywany gdzie indziej konieczne jest podanie pełnej ścieżki dostępu, ale można w tym wypadku korzystać z autouzupełniania klawiszem Tab. 3.1.1 Wczytanie danych z plików tekstowych R Studio posiada funkcję Import Dataset (zakładka Environment), która pozwala na wczytanie danych wraz z wyborem podstawowych opcji jak separator, separator dziesiętny, obecność nagłówków. Opcja ta obejmuje podstawowe funkcje R oraz pakiety readr i readxl będące częścią tidyverse. Na początek jest łatwiej korzystać z opcji Load Dataset, ponieważ po jej użyciu zostaje również wygenerowany odpowiedni kod R, który można wkleić do własnych skryptów tak aby te same lub podobne dane wczytać już bez problemu następnym razem. Można również wczytać dane wpisując komendę (wygodne przy pisaniu skryptów) read.table albo read.csv. Argumenty: file określa nam plik, który wczytujemy, header - nagłówki, sep - separator np. “/t” to tabulator, dec - separator dziesiętny (domyślnie kropka), quote - obecność \"\". W przypadku nagłówków kolumn wpisanie header=TRUE spowoduje, że pierwszy wiersz naszej tabeli zostanie potraktowany jako tytuły kolumn, header=FALSE oznacza domyślne nazwy kolumn - V1, V2, … W pakiecie readr znajdują się analogiczne funckje: * read_delim - do plików tekstowych, funckja spróbuje zgadnąć jak rozdzielone są kolumny, można podać argumentem delim * read_csv i read_csv2 - do plików csv, odpowiednio do danych wykorzystujących kropki i przecinki jako separatory dziesiętne * read_tsv i read_table - do plików gdzie kolumny są rodzielone przy pomocy tab. Wczytane dane będą widoczne w zakładce Environment. Kliknięcie na nazwę tabeli spowoduje otwarcie widoku danych podobnego do arkusza kalkulacyjnego. Można w nim dane sortować i filtrować, ale nie edytować. Pierwsze albo ostanie wiersze można zobaczyć używając funkcji head albo tail. Strukturę danych pokaże funkcja str, a podstawowe informacje summary. Dobrze jest po wczytaniu danych sprawdzić czy wyglądają faktycznie tak jak miały ;) dane1 &lt;- read.table(file = &quot;data/dane1.txt&quot;, header=TRUE, quote=&quot;\\&quot;&quot;) head(dane1) ## pomiar Szczep warunki ## 1 3.389738 A 1 ## 2 5.992065 A 1 ## 3 4.464553 A 1 ## 4 4.546082 A 1 ## 5 6.521751 A 1 ## 6 5.713088 A 1 str(dane1) ## &#39;data.frame&#39;: 1800 obs. of 3 variables: ## $ pomiar : num 3.39 5.99 4.46 4.55 6.52 ... ## $ Szczep : chr &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... ## $ warunki: int 1 1 1 1 1 1 1 1 1 1 ... summary(dane1) ## pomiar Szczep warunki ## Min. : 1.434 Length:1800 Min. :1.0 ## 1st Qu.: 4.450 Class :character 1st Qu.:1.0 ## Median : 5.478 Mode :character Median :1.5 ## Mean : 5.846 Mean :1.5 ## 3rd Qu.: 6.743 3rd Qu.:2.0 ## Max. :27.953 Max. :2.0 3.1.2 Wczytanie danych z plików excel Do wczytania danych z plików xlsx można wykorzystać funkcję read_excel z pakietu readxl. Przy pracy z excelem należy jednak pamiętać żeby wczytywane dane nie zawierały formuł albo połączonych komórek oraz, że funkcja wczyta dane zawarte tylko w jednym arkuszu (sheet), ale można wybrać z której przy pomocy argumentu sheet. library(readxl) data_excel &lt;- read_excel(&#39;data/test.xlsx&#39;) data_excel ## # A tibble: 16 × 3 ## A B C ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 ## 2 1 3 4 ## 3 1 4 5 ## 4 1 5 6 ## 5 1 6 7 ## 6 1 7 8 ## 7 1 8 9 ## 8 1 9 10 ## 9 1 10 11 ## 10 1 11 12 ## 11 1 12 13 ## 12 1 13 14 ## 13 1 14 15 ## 14 1 15 16 ## 15 1 16 17 ## 16 1 17 18 3.2 Zapisanie danych Zapisać tabelę danych można korzystając z funkcji write.table, wystarczy określić, co chcemy zapisać i nazwę pliku wyjściowego. Możemy zapisywać pliki w formacie np. txt, csv. Jeżeli nie określimy ścieżki dostępu plik zostanie zapisany w folderze projektu. Można również dopisywać dane do istniejącego pliku ustawiając parametr append = TRUE. Domyślnie ten argument jest zawsze ustawiony jako append = FALSE i jeżeli w nazwie pliku podamy istniejący plik to zostanie on nadpisany bez ostrzeżenia. Można też dane zapisać w formacie rds. Można je potem otworzyć tylko w R, ale można w takim formacie zapisać każdy obiekt R, nie tylko tabele. Do zapisania danych służy funkcja saveRDS, a do wczytanie readRDS. write.table(dane1, &quot;data/dane4.txt&quot;) 3.3 Podstawowe typy danych w R W R dane do zmiennej przypisujemy korzystając ze strzałki ;) &lt;- albo -&gt;. Można też użyć = Do najbardziej podstawowych typów danych należą: typ liczbowy, znakowy, logiczny i czynnikowy (o tym później). Typ danych można sprawdzić funkcją class Najczęściej wykorzystywane rodzaje danych to wektor i ramka danych. Pozostałe to m.in. macierz i lista. W R można również pisać własne funkcje. 3.3.1 Wektor (vector) Wektor to ciąg elementów tego samego typu np. liczbowy, znakowy. W R nawet pojedyncza cyfra jest wektorem. Wektor można stworzyć korzystając z funkcji: c. Sekwencję liczb można zapisać jako 1:10 - utworzy wektor liczb od 1 do 10. Przy bardziej skomplikowanych sekwencjach można użyć funkcji seq, ustawiamy start, koniec i co ile ma być kolejny element funkcję rep, podajemy jakie elementy mają zostać powtórzone i ile razy. each - powtarzanie każdego elementu, times - powtarzanie całego wektora. a &lt;- c(1,2,5,8) a ## [1] 1 2 5 8 b &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;V&quot;) b ## [1] &quot;A&quot; &quot;B&quot; &quot;V&quot; c &lt;- 1:15 c ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 d &lt;- seq(10, 100, by=10) d ## [1] 10 20 30 40 50 60 70 80 90 100 e &lt;- rep(c(1,2,3), times=3) e ## [1] 1 2 3 1 2 3 1 2 3 e &lt;- rep(c(1,2,3), each=3) e ## [1] 1 1 1 2 2 2 3 3 3 Do poszczególnych elementów wektora można się odwołać stosując nawiasy: wektor[x], gdzie x to numer elementu. Można się odwołać do kilku elementów jednocześnie np. wektor[1:3], wektor[c(2,4)]. Numeracja rozpoczyna się od 1. Elementy wektora mogą również mieć swoje nazwy i wtedy można je także wykorzystać do wyświetlania danych. Ilość elementów wektora podaje funkcja length. a &lt;- c(1:5) a[2] ## [1] 2 b &lt;- c( &quot;jeden&quot; = 1, &quot;dwa&quot; = 2, &quot;trzy&quot; = 3) b[2] ## dwa ## 2 b[&quot;dwa&quot;] ## dwa ## 2 length(a) ## [1] 5 Na wektorach można wykonywać wszystkie operacje matematyczne. Przykładowo jeżeli dodamy do siebie dwa wektory to zawsze pierwszy element zostanie dodany do pierwszego elementu z drugiego wektora itd. 1:10 + 11:20 ## [1] 12 14 16 18 20 22 24 26 28 30 1:10 * 11:20 ## [1] 11 24 39 56 75 96 119 144 171 200 3.3.2 Ramka danych (data frame) Ramka danych to po prostu kilka wektorów ułożonych w tabelę. Wektory mogą być różnego typu, powinny być tej samej długości. Jeżeli mają różną długość można uzupełnić brakujące elementy stosując NA - brak danych Skoro każda kolumna ramki danych jest wektorem to można stosować na nich te same operacje matematyczne np. dodawać albo dzielić. Ramkę danych tworzymy przy użyciu funkcji data.frame Jeżeli chcemy coś zmienić w ramkę danych używamy as.data.frame Podstawowe informacje o ramce danych Funkcja Opis nrow liczba wierszy ncol liczba kolumn colnames nazwy kolumn rownames nazwy wierszy dim wymiary x &lt;- data.frame(a=1:5, b=rep(&quot;A&quot;,5), c=c(T,T,T,F,NA)) x ## a b c ## 1 1 A TRUE ## 2 2 A TRUE ## 3 3 A TRUE ## 4 4 A FALSE ## 5 5 A NA colnames(x) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; Do elementów ramki danych również można się odwołać przy pomocy nawiasów: ramka[x,y], gdzie x to numer wiersza, a y numer kolumny. Jeżeli podamy jedynie numer kolumny otrzymamy wszystkie jej elementy. Innym sposobem jest wykorzystanie nazw kolumn i $ np ramka$kolumna_1. W ten sposób można łatwo dodać nowe kolumny do ramki danych. Podobnie możemy usuwać kolumny i wiersze z ramki np. ramka&lt;-ramka[,-1] usunie pierwszą kolumnę. ramka &lt;- data.frame(kol1=c(1:10), kol2=c(11:20)) ramka ## kol1 kol2 ## 1 1 11 ## 2 2 12 ## 3 3 13 ## 4 4 14 ## 5 5 15 ## 6 6 16 ## 7 7 17 ## 8 8 18 ## 9 9 19 ## 10 10 20 ramka$kol_3 &lt;- ramka$kol1 + ramka$kol2 ramka ## kol1 kol2 kol_3 ## 1 1 11 12 ## 2 2 12 14 ## 3 3 13 16 ## 4 4 14 18 ## 5 5 15 20 ## 6 6 16 22 ## 7 7 17 24 ## 8 8 18 26 ## 9 9 19 28 ## 10 10 20 30 Funkcje zawarte w pakietach tidyverse (w tym read_delim i inne) często zamiast zwykłej ramki danych używają ulepszonej struktury zwanej tibble. W codziennym użytkowaniu nie ma między nimi wielu różnic. Tibble są bezpieczniejsze od zwykłych data.frame, ponieważ nigdy nie zmieniają typów danych w kolumnach. Może się jednak czasem zdarzyć że funkcje starszych pakietów nie będą akceptować tibble zamiast data.frame (można łatwo zmienić przy pomocy as.data.frame. 3.3.3 Matryca (matrix) Matryca jest trochę podobna do ramki danych, ale może zawierać tylko jeden typ danych np. liczbowe. Może mieć więcej wymiarów niż dwa. Tworzymy funkcją matrix, zmiana istniejących danych na matrycę - as.matrix. Indeksowanie z matrycach działa tak samo jak w ramkach danych - [wiersz, kolumna]. matrix(0, 4, 5) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## [3,] 0 0 0 0 0 ## [4,] 0 0 0 0 0 matrix(1:15, 3, 5) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 4 7 10 13 ## [2,] 2 5 8 11 14 ## [3,] 3 6 9 12 15 (x &lt;- matrix(1:9, 3,3)) ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 x[1,3] ## [1] 7 3.3.4 Lista (list) Lista to taki rozbudowany wektor ;) i najbardziej elastyczny typ danych w R. Każdy element listy może być innego rodzaju, mieć inną długość, można stworzyć listę, której elementami będzie np. ramka danych, wektor, wykres i nawet inna lista. Listę tworzymy funkcją list, podobnie jak w wektorze każdy element może mieć swoją nazwę. Wiele funkcji jako swój wynik zwraca listę, więc często przydaje się wiedza jak dostać się do poszczególnych elementów. Funkcją str możemy wyświetlić podsumowanie wszystkich elementów listy. Do poszczególnych części można dostać się przez nazwy albo indeksowanie [] albo [[]]. Przy zastosowaniu nawiasów [] uzyskany element nadal będzie częścią listy. lista &lt;- list( ramka = data.frame(a=rnorm(10), b=&quot;test&quot;), wektor = seq(1,16,by=3), tekst = &quot;To jest lista&quot; ) lista ## $ramka ## a b ## 1 0.2466945 test ## 2 -0.4012535 test ## 3 -0.1112687 test ## 4 -0.8496192 test ## 5 0.4300758 test ## 6 0.7411146 test ## 7 -1.1603034 test ## 8 1.7738915 test ## 9 -0.8328937 test ## 10 1.3048231 test ## ## $wektor ## [1] 1 4 7 10 13 16 ## ## $tekst ## [1] &quot;To jest lista&quot; str(lista) ## List of 3 ## $ ramka :&#39;data.frame&#39;: 10 obs. of 2 variables: ## ..$ a: num [1:10] 0.247 -0.401 -0.111 -0.85 0.43 ... ## ..$ b: chr [1:10] &quot;test&quot; &quot;test&quot; &quot;test&quot; &quot;test&quot; ... ## $ wektor: num [1:6] 1 4 7 10 13 16 ## $ tekst : chr &quot;To jest lista&quot; lista$tekst ## [1] &quot;To jest lista&quot; lista[3] ## $tekst ## [1] &quot;To jest lista&quot; lista[[3]] ## [1] &quot;To jest lista&quot; # pierwszy element wektora, będącego drugim elementem listy lista[[2]][1] ## [1] 1 3.3.5 Typ liczbowy (numeric), znakowy (character), logiczny (logical) Typ liczbowy przechowuje liczby całkowite i rzeczywiste. Kropką dziesiętną jest kropka :). Na liczbach można łatwo prowadzić podstawowe działania matematyczne - dodawanie, odejmowanie, mnożenie itp. Takie same operacje możemy prowadzić na wektorach. 2*4 ## [1] 8 A &lt;- c(2,4,6) B &lt;- c(1,2,3) A*B ## [1] 2 8 18 Typ znakowy zawiera napisy umieszczone pomiędzy \"\" albo ’’. Napisy można wyświetleć np. funkcją cat, możemy wymusić pisanie kolejnego elementu w nowej linii poprzez \"\\n\". Sklejanie np. tekstu i liczb można wykonać funkcją paste. Do pracy z typem znakowym można wykorzystać pakiet stringr. &quot; To jest napis &quot; ## [1] &quot; To jest napis &quot; cat(&quot;coś&quot;, &quot;tam&quot;) ## coś tam cat(&quot; coś&quot;,&quot;\\n&quot;,&quot;tam&quot;) ## coś ## tam a &lt;- 1 cat(&quot;Wynik to&quot;, a) ## Wynik to 1 paste(&quot;Wynik równa się&quot;, a) ## [1] &quot;Wynik równa się 1&quot; Typ logiczny przechowuje tylko wartości: TRUE (T) i FALSE (F) oraz NA (brak danych). Nazwy TRUE i FALSE są w R zastrzeżone, ale T i F już nie. Dlatego lepiej używać pełnych nazw, bo może się zdarzyć, że do T albo F zostanie przypisana jakaś zmienna. wektor &lt;- c(TRUE, FALSE, TRUE) wektor ## [1] TRUE FALSE TRUE summary(wektor) ## Mode FALSE TRUE ## logical 1 2 3.3.6 Typ czynnikowy (factor) Służy do przechowywania wartości występujących w kilku kategoriach np. płeć, wykształcenie itp. Podczas wczytywania danych R z wykorzystaniem podstawowych funckji, ale nie z pakietu readr, automatycznie zamieni kolumny zawierające tekst na typ czynnikowy, chyba że zaznaczymy opcję stringAsFactors=FALSE. Typ czynnikowy jest przydatny podczas robienia wykresów, gdy chcemy pogrupować dane pod względem jakiejś kategorii. Również legendy (kolejność elementów) są tworzone w oparciu o poziomy czynnika. Może się zdarzyć, że kolejność wybrana przez R (często alfabetyczna) nie będzie odpowiednia. Można łatwo przestawić poziomy korzystając z funkcji factor. W tej samej funkcji argument labels pozwala na zmianę nazw kolejnych poziomów. Jeżeli chcemy zmienić kolejność elementów na wykresie np. boxplotów, słupków najlepiej zrobić to zmieniając poziomy faktora w danych. Poziomy factor można wyświetlić przy pomocy funkcji levels. Do pracy z typem czynnikowym można wykorzystać pakiet forcats będący częścią tidyverse. faktor &lt;- factor(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;A&quot;, &quot;A&quot;,&quot;C&quot;)) faktor ## [1] A B C A A C ## Levels: A B C str(faktor) ## Factor w/ 3 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;: 1 2 3 1 1 3 levels(faktor) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; summary(faktor) ## A B C ## 3 1 2 # Zmiana poziomów faktor2 &lt;- factor(faktor, levels=c(&quot;B&quot;, &quot;C&quot;, &quot;A&quot;), labels = c(&quot;BB&quot;, &quot;CC&quot;, &quot;AA&quot;)) faktor2 ## [1] AA BB CC AA AA CC ## Levels: BB CC AA 3.3.7 Funkcje Większość operacji na danych w R wykonujemy za pomocą funkcji. Pakiety są to właściwie zbiory funkcji, często dotyczących jednego konkretnego zagadnienia. Każda funkcja zawiera przynajmniej jeden argument, który jest niezbędny do jej działania. Nazwy wszystkich argumentóœ możemy sprawdzić korzystając z pomocy. Często nie jest konieczne podanie wartości wszystkich argumentów, gdyż mogą mieć ustawione wartości domyślne. Jeżeli podajemy wartości argumentóœ możemy je wpisywać do funkcji kolejno (tak jak są wypisane w pomocy) albo korzystając z nazw. Jeżeli nie pamiętamy wszystkich nazw można sobie pomóc przy pomocy klawisza Tab :) Kolejne podawane argumenty należy rozdzielać przecinkami np. funkcja(a=1, b=2, c=\"model\"). Do argumentu możemy też podać wektor wartości korzystając z c np. funkcja(a=c(1,2,5)) Np. funkcja licząca średnią to mean. Zawiera trzy argumenty: x - oznacza obiekt, z którego ma być policzona średnia trim (domyślnie 0) oznacza część obserwacji, która ma zostać przycięta z każdej strony x na.rm (domyślnie FALSE) - czy mają być brane pod uwagę wartości NA. ?mean mean {base} R Documentation Arithmetic Mean Description Generic function for the (trimmed) arithmetic mean. Usage mean(x, ...) ## Default S3 method: mean(x, trim = 0, na.rm = FALSE, ...) wek &lt;- c(1,5,9,2,7,3,5,9,2,4) mean(wek) ## [1] 4.7 mean(x=wek) ## [1] 4.7 mean(x=wek, trim=0.2, na.rm=TRUE) ## [1] 4.333333 W R możliwe jest pisanie własnych funkcji. Nie jest to trudne, a pozwala na uniknięcie wielokrotnego powtarzanie tego samego kodu. Dużo łatwiej jesy zmienić/poprawić jedną funkcję niż dwadzieścia razy wklejone te same 10 linijek kodu :) Poniżej krótki przykład tworzenia funkcji. Więcej informacji można znaleźć np. w książce R for Data Science. Załóżmy że chemy napisać funckję która wczyta dane z pliku txt i doda do tego pliki nową kolumnę będącą sumą dwóch pierwszych. Kod potrzebny żeby to wykonać: data &lt;- read.table(&#39;data/test_funkcja.txt&#39;) data$nowa_kolumna &lt;- data$x + data$y A teraz funckja która wykonuje te same czynności. Nazwa funkcji jest dowolna, chociaż lepiej jest nie nadpisywać już istniejących funkcji, a jej nazwa powinna opisywać to co funkcja będzie robić. W nawiasach () należy podać nazwy argumentów z ewentualnymi wartościami domyślnymi, a w nawiadach {} kod który ma zostać wykonany. Na końcu funkcji warto użyć return() - determinuje jaki wynik zwróci funkcja. dodaj_kolumne &lt;- function(file){ data &lt;- read.table(file) data$nowa_kolumna &lt;- data$x + data$y return(data) } Każdą funkcję po napisaniu należy sprawdzić dodaj_kolumne(&#39;data/test_funkcja.txt&#39;) ## x y nowa_kolumna ## 1 1 11 12 ## 2 2 12 14 ## 3 3 13 16 ## 4 4 14 18 ## 5 5 15 20 ## 6 6 16 22 ## 7 7 17 24 ## 8 8 18 26 ## 9 9 19 28 ## 10 10 20 30 "],["wykresy---pakiet-ggplot2.html", "Chapter 4 Wykresy - pakiet ggplot2 4.1 Używane dane 4.2 Histogram, boxplot i inne 4.3 Barplot - wykres słupkowy 4.4 Średnia, mediana itp. na wykresie 4.5 Wykres punktowy i liniowy 4.6 Kolory, osie, panele 4.7 Motyw (theme) 4.8 Różne 4.9 Rozszeżenia ggplot2", " Chapter 4 Wykresy - pakiet ggplot2 ## ## If anything, there should be a Law: Thou Shalt Not Even Think Of Producing A ## Graph That Looks Like Anything From A Spreadsheet. ## -- Ted Harding (in a discussion about producing graphics) ## R-help (August 2007) Do tworzenia wykresów można użyć kilku pakietów: graphics - podstawowy pakiet graficzny instalowany razem z R, pełna kontrola nad wyglądem wykresu, ale często wymaga to więcej pracy niż w innych pakietach. Przydatny jeżeli chcemy coś szybko sprawdzić, a nie interesuje nas wygląd wykresu, niektóre wykresy można stworzyć tylko w tym pakiecie lattice - umożliwia łatwe tworzenie kilku wykresów na raz np. do porównania różnych cech, ale obecnie mniej popularny niż np. ggplot2 ggplot2 - jeden z najpopularniejszych pakietów R i mój ulubiony do przygotowywania wykresów. Oparty na grammar of graphics. Przygotowanie “ładnych” wykresów wymaga mniej pracy niż w podstawowym, ale składnia jest znacząco różna. Łatwe porównywanie i tworzenie kilku wykresów na jednym obrazku plotly - pozwala na tworzenie interaktywnych wykresów np. do wykorzystania na stronach www lub w shiny. Pakiet ggplotly umożliwia konwersję wykresów ggplot do postaci interaktywnej Wykresy w ggplot2 składają się z kilku elementów: data, aesthetics, geom, scale, facet, theme itd. Pierwsze trzy są niezbędne do przygotowania wykresu. Poszczególne elementy można ze sobą łączyć na różne sposoby, co pozwala w prosty sposób robić bardzo różne wykresy. Podstawowa funkcja : ggplot(). W niej określany jest tylko data i aesthetic, pozostałe elementy dodawane są przy pomocy + data - określa ramkę danych, na podstawie której będzie przygotowany wykres, najlepiej żeby była w formacie ‘tidy’ aesthetics (aes) - pokazuje (mapuje), które kolumny mają być wykorzystane np. x=kolumna_1 dla histogramu, można też określać pod względem których zmiennych dane mają zostać pogrupowane (group), rozróżnione (color, fill, shape itp) np. aes(x = kolumna_1, color = kolumna_2) znaczy że dane z kolumny_1 zostaną wykorzystane do stowrzenia osi X, a dane z kolumny_2 posłużą do stowrzenia skali kolorów. geom - rodzaj wykresu - to co widzimy - np histogram, density, bar, boxplot, point, line itp., można użyć kilka jednocześnie np. point i line, histogram i density scale - osie wykresu np. czy mają być logarytmiczne, procentowe, miejsce start i koniec, ale też skale kolorów, wypełnienia, kształtów itp. facet - umożliwia podział wykresu na kilka mniejszych pod względem danej zmiennej theme - wygląd poszczególnych elementów wykresu (motyw) np. czcionki, rodzaj linii, kolor tła, legenda itp., istnieje sporo już przygotowanych. Można przygotować własny i zapisać - łatwo można zrobić kilka wykresów w jednym stylu Istnieje również funkcja qplot, która jest podobna do funkcji plot w podstawowym R, ale jej możliwości są uboższe w porównaniu z ggplot. Wykresy ggplot są przypisywane do zmiennych np p &lt;- ggplot(...), zmienna p przechowuje wszystkie dane dotyczące wykresu. Możemy je sprawdzić funkcją summary. Dodanie kolejnych elementów do wykresu np. p + geom_point(), jeżeli chcemy nadpisać dotychczasowy wykres - p &lt;- p + geom_point(). Korzystając z + możemy dodawać tyle elementów ile chcemy. 4.1 Używane dane Dane 1 opisują jakąś cechę zmierzoną dla trzech szczepów w dwóch rodzajach warunków. library(ggplot2) # ładujemy niezbędne pakiety library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union dane1 &lt;- read.table(&quot;data/dane1.txt&quot;, header = TRUE, quote = &quot;\\&quot;&quot;) head(dane1) ## pomiar Szczep warunki ## 1 3.389738 A 1 ## 2 5.992065 A 1 ## 3 4.464553 A 1 ## 4 4.546082 A 1 ## 5 6.521751 A 1 ## 6 5.713088 A 1 Dane 2 zawierają ten sam zestaw szczepów i warunków, ale tym razem zostały one podzielone na 4 grupy: tak, nie, może i NA (brak danych). dane2 &lt;- read.table(&quot;data/dane2.txt&quot;, header = TRUE, quote = &quot;\\&quot;&quot;) head(dane2) ## pomiar Szczep warunki ## 1 Tak A 1 ## 2 Nie A 1 ## 3 Tak A 1 ## 4 Tak A 1 ## 5 &lt;NA&gt; A 1 ## 6 Tak A 1 summary(dane2) ## pomiar Szczep warunki ## Length:1200 Length:1200 Min. :1.0 ## Class :character Class :character 1st Qu.:1.0 ## Mode :character Mode :character Median :1.5 ## Mean :1.5 ## 3rd Qu.:2.0 ## Max. :2.0 Dane 3 to wzrost dwóch szczepów w trzech powtórzeniach w czasie 1-100. dane3 &lt;- read.table(&quot;data/dane3.txt&quot;, header = TRUE, quote = &quot;\\&quot;&quot;) head(dane3) ## pomiar Szczep powt czas ## 1 0.09639497 A 1 1 ## 2 0.11830818 A 1 2 ## 3 0.11839652 A 1 3 ## 4 0.13904646 A 1 4 ## 5 0.15544315 A 1 5 ## 6 0.13080412 A 1 6 summary(dane3) ## pomiar Szczep powt czas ## Min. :0.09175 Length:1200 Min. :1 Min. : 1.00 ## 1st Qu.:0.33428 Class :character 1st Qu.:1 1st Qu.: 25.75 ## Median :0.52688 Mode :character Median :2 Median : 50.50 ## Mean :0.54175 Mean :2 Mean : 50.50 ## 3rd Qu.:0.74753 3rd Qu.:3 3rd Qu.: 75.25 ## Max. :1.10474 Max. :3 Max. :100.00 Dane tego typu możemy przedstawić jako wykres np. liniowy, punktowy, ribbon (liniowy z zaznaczonym błędem, przedziałem ufności itp.). 4.2 Histogram, boxplot i inne 4.2.1 Histogram i density theme_set(theme_bw()) # żeby wszystkie wykresy miały białe tło, a nie szare - będzie o tym później dane1_1 &lt;- subset(dane1, Szczep == &quot;A&quot; &amp; warunki == &quot;1&quot;) p &lt;- ggplot(data = dane1_1, aes(x = pomiar)) p + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Dla histogramu najważniejszy parametr to binwidth określający szerokość “słupków.” Możemy też wybrać czy chcemy żeby były zliczane ilości elementów (domyślnie), czy ma być pokazana gęstość rozkładu - w aes należy wpisać y=..density.. albo procenty y=((..count..)/sum(..count..))*100 (w przypadku procentów lepiej jednak policzyć je wcześniej i podać już gotowe wartości do ggplot, w bardziej skomplikowanych przypadkach ggplot może sobie nie poradzić). Do dodania znaków % potrzebna jest zmiana parametrów osi, o tym później. Można też zmienić kolor wypełnienia słupków - fill lub kolor linii - color. p + geom_histogram(binwidth = 0.5) # Histogram z gęstością na osi Y p + geom_histogram(binwidth = 0.5, aes(y = ..density..)) # Histogram z wartością % na osi Y p + geom_histogram(binwidth = 0.5, aes(y = ((..count..)/sum(..count..)*100))) # Zmiana koloru wypełnienia histogramu p + geom_histogram(binwidth = 0.5, aes(y = ..density..), fill = &quot;lightgreen&quot;, color = &quot;black&quot;) # Dodanie wszystkich obserwacji do wykresu - geom_rug() p + geom_histogram(binwidth = 0.5, aes(y = ..density..), fill = &quot;lightgreen&quot;, color = &quot;black&quot;)+ geom_rug() Histogram możemy łatwo zmienić na geom_density (gęstość) albo połączyć oba na jednym wykresie (należy pamiętać żeby ujednolicić oś Y - w histogramie ustawić y=..density.. albo w density y = ..count..) Wykresy gęstości są dużo czytelniejsze od histogramów przy większej liczbie grup/kolorów na wykresie. p + geom_density() # Wykres łączący histogram i gęstość p + geom_histogram(binwidth = 0.5, aes(y = ..density..))+ geom_density(color = &quot;red&quot;) # albo tak, ale wtedy trzeba count w density podzielić przez coś - konkretną liczbę lepiej dobrać indywidualnie do każdego wykresu p + geom_histogram(binwidth = 0.5)+ geom_density(color = &quot;red&quot;, aes(y = ..count../2)) # Zamiast density można też użyć geom_freqpoly, który da bardziej &quot;kanciasty&quot; wykres # Wymaga parametru binwidth tak samo jak histogram p + geom_freqpoly(binwidth = 0.5) 4.2.2 Wykres pudełkowy - boxplot Na wykresie pudełkowym linia obrazuje medianę, pudełko to przestrzeń między 1 i 3 kwantylem, wąsy to zakres danych, a wszystkie punkty to obserwacje odstające. Zamiast histogramu możemy zrobić boxplot, w tym wypadku x to nazwa szczepu, a y to mierzona cecha. Na osi X należy zawsze umieszczać zmienną jakościową, a na osi Y zmienną ilościową # pojedynczy boxplot p &lt;- ggplot(data = dane1_1, aes(x = &quot;Szczep A&quot;, y = pomiar)) p + geom_boxplot() # boxplot dla każdej kategorii p &lt;- ggplot(data = dane1, aes(x = Szczep, y = pomiar)) p + geom_boxplot() # do boxplota można dodać wcięcia, jeżeli wcięcia dwóch boxplotów na siebie nie zachodzą # można uznać że mediany tych dwóch grup są od siebie znacząco różne p + geom_boxplot(notch = TRUE) 4.2.3 Wykres skrzypcowy Odmianą boxplotów są tzw. wykresy skrzypcowe, które pozwalają też na pokazanie kształtu rozkładu - pozwala to np. na wykrycie rozkładu, który ma dwa maksima. W ggplot2 można je wygenerować funkcją geom_violin. p &lt;- ggplot(data=dane1, aes(x = Szczep, y = pomiar)) p + geom_violin(aes(color = factor(warunki))) # przykładowe dane dane &lt;- data.frame(x = c(rnorm(100), rnorm(100, 3), rnorm(100, 1), rnorm(100, 5)), faktor = rep(c(&quot;A&quot;, &quot;B&quot;), each = 200)) p &lt;- ggplot(data = dane, aes(y = x, x = faktor, fill = faktor)) p + geom_violin() # nie przyciety wykres p + geom_violin(trim=FALSE) 4.2.4 Dodanie wszystkich obserwacji do boxplot/violin Dobrą praktyką jest przy używaniu wykresów pudełkowych lub skrzypcowych pokazanie wszystkich uzyskanych obserwacji (o ile nie ma ich za dużo). Można w tym celu użyć funkcji geom_jitter albo ładniejszych geom_beeswarm i geom_quasirandom z pakietu ggbeeswarm. Przy pomocy argumentu alpha można kontrolować przezroczystość punktów - przydatne gdy jest ich dużo. dane1_2 &lt;- dane1 %&gt;% filter(warunki == 1) # Boxplot dla każdego szczepu p &lt;- ggplot(data = dane1_2, aes(x = Szczep, y = pomiar)) p + geom_boxplot(aes(color = Szczep))+ geom_jitter(aes(color = Szczep), alpha = 0.2) # usuwamy punkty pochodzące od boxplota p + geom_boxplot(aes(color = Szczep), outlier.alpha = 0)+ geom_jitter(aes(color = Szczep), alpha = 0.2) # beeswarm library(ggbeeswarm) p + geom_boxplot(aes(color = Szczep), outlier.alpha = 0)+ geom_beeswarm(aes(color = Szczep), alpha = 0.2) # quasirandom p + geom_boxplot(aes(color = Szczep), outlier.alpha = 0)+ geom_quasirandom(aes(color = Szczep), alpha = 0.2) # quasirandom + geom_violin p &lt;- ggplot(data=dane1, aes(x = Szczep, y = pomiar)) p + geom_violin(aes(color = factor(warunki)))+ geom_quasirandom(aes(color = factor(warunki)), dodge.width = 0.9, # pozwala na rodział kolorów na dwie grupy alpha = 0.1) Można też połączyć wszystko w całość korzystając z dodatkowych pakietów ggdist i gghalves, na podstawie strony: visualizing-distributions-with-raincloud-plots-with-ggplot2 ggplot(dane1_2, aes(x = Szczep, y = pomiar, color = Szczep, fill = Szczep)) + ggdist::stat_halfeye( adjust = .5, width = .6, .width = 0, justification = -.2, point_colour = NA ) + geom_boxplot( width = .15, outlier.shape = NA, alpha = 0.2 ) + ## add justified jitter from the {gghalves} package gghalves::geom_half_point( ## draw jitter on the left side = &quot;l&quot;, ## control range of jitter range_scale = .4, ## add some transparency alpha = .3 ) 4.2.5 Dotplot Wykres, na którym obserwacje są zaznaczane jako punkty, może być alternatywą dla histogramu albo gęstości jeżeli mamy małą liczbę danych. Punkty mogą być układane na którejś z osi albo wyśrodkowane. Podobnie jak w histogramie możemy określić parametrem binwidth jak mają być ułożone punkty. dane_dot &lt;- data.frame(pomiar = c(rnorm(20), rlnorm(20), runif(20)), kategoria = rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;), each = 20)) p &lt;- ggplot(dane_dot) p + geom_dotplot(aes(x = pomiar)) ## Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`. p + geom_dotplot(aes(x = pomiar), binwidth = 0.25) # możemy kropki pokolorować według kategorii, # konieczne parametry stackgroups=TRUE i binpositions=&quot;all&quot; p + geom_dotplot(aes(x = pomiar, fill = kategoria), binpositions = &quot;all&quot;, stackgroups = TRUE) ## Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`. # albo przedstawić każdą kategorię osobno, binaxis określa w jakim kierunku układać kropki, # stackdir czy mają być wyśrodkowane - center lub centerwhole p + geom_dotplot(aes(y = pomiar, x = kategoria), stackdir = &quot;center&quot;, binaxis = &quot;y&quot;, binwidth = 0.2) # zmiana wielkości kropki przez dotsize p + geom_dotplot(aes(y = pomiar, x = kategoria), stackdir = &quot;center&quot;, binaxis = &quot;y&quot;, binwidth = 0.2, dotsize = 0.75) # można też wybrać metodę układania kropek, domyślnie wedle gęstości, # podobnie jak histogram - method=&quot;histodot&quot; p + geom_dotplot(aes(y = pomiar, x = kategoria), stackdir = &quot;center&quot;, binaxis = &quot;y&quot;, binwidth = 0.2, dotsize = 0.75, method = &quot;histodot&quot;) 4.3 Barplot - wykres słupkowy Szybkie zliczenie elementów w poszczególnych grupach możemy wykonać stosując funkcję table. Wystarczy podać jej kolumnę z danymi oraz kolumny zawierające wektory według których dane mają zostać podzielone na grupy. Wynikiem table nie jest ramka danych, więc bez przekształcenia nie można go użyć do przygotowania wykresu ggplot. table(dane2$pomiar) ## ## Może Nie Tak ## 224 469 437 table(dane2$pomiar, dane2$Szczep, dane2$warunki) ## , , = 1 ## ## ## A B C ## Może 19 25 38 ## Nie 68 94 123 ## Tak 94 71 21 ## ## , , = 2 ## ## ## A B C ## Może 51 23 68 ## Nie 15 67 102 ## Tak 134 93 24 Można zauważyć, że funkcja table, w przeciwieństwie do summary pominęła wartości oznaczone jako NA. Można to zmienić używając parametr useNA. table(dane2$pomiar, dane2$Szczep, dane2$warunki, useNA = &quot;ifany&quot;) ## , , = 1 ## ## ## A B C ## Może 19 25 38 ## Nie 68 94 123 ## Tak 94 71 21 ## &lt;NA&gt; 19 10 18 ## ## , , = 2 ## ## ## A B C ## Może 51 23 68 ## Nie 15 67 102 ## Tak 134 93 24 ## &lt;NA&gt; 0 17 6 Wykres słupkowy wymaga użycia geom_bar. Zasady rozróżniania zmiennych według kolorów i dzielenia wykresów na części pozostają takie same. Domyślnie również wartości NA zostaną wzięte pod uwagę podczas zliczania. Jeżeli chcemy temu zapobiec, należałoby np. usunąć je wcześniej przy pomocy funkcji filter. p &lt;- ggplot(data = dane2, aes(x = pomiar, fill = Szczep)) # Słupki ustawione obok siebie p + geom_bar(position = &quot;dodge&quot;) + facet_wrap(~ warunki) # Wszystkie słupki tej samej wysokości p + geom_bar(position = &quot;fill&quot;) + facet_wrap(~ warunki) # Szerokość słupków można zmieniać parametrem width p + geom_bar(position = &quot;dodge&quot;, width = 0.4) + facet_wrap(~ warunki) # Wykres bez wartości NA, filter można zrobić też wcześniej albo w obrębie ggplot p &lt;- ggplot(dane2 %&gt;% filter(!is.na(pomiar)), aes(x = pomiar, fill = Szczep)) p + geom_bar(position = &quot;dodge&quot;) + facet_wrap(~ warunki) Przy dużej ilości różnokolorowych słupków wykres może być trudny do odczytania. Można wtedy rozważyć zastosowanie dotchart - czyli wykresu na którym wartości zliczenia są oznaczane przez pojedyncze punkty, a nie przez wysokość słupków. W ggplot2 do zrobienia dotchart możemy użyć geom_point # Ustawiamy stat=&quot;bin&quot; - oznacza że ggplot ma zliczyć częstości występowania elementów, # a nie narysować każdy z osobna i obracamy wykres - ułatwia odczytanie p + geom_point(size=3, stat=&#39;count&#39;, aes(color=Szczep))+ facet_wrap(~warunki)+coord_flip() Nasze dane mogą też zawierać wysokości słupków. W takim wypadku należy użyć geom_col x &lt;- data.frame(x = c(2, 6, 3, 8, 9), name = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;)) p &lt;- ggplot(data = x, aes(x = name, y = x)) p + geom_col(aes(fill = name)) 4.4 Średnia, mediana itp. na wykresie 4.4.1 Stat_summary Możemy również potrzebować wykres z zaznaczoną średnią i przedziałem ufności albo błędem standardowym. W takim wypadku możemy sami policzyć te wartości, a następnie pokazać je używając geom_pointrange albo geom_crossbar. Można też wykorzystać stat_summary, który policzy je za nas. W stat_summary najważniejszym argumentem jest funkcja jaką zastosujemy do podsumowania danych. Może to być albo fun.y - należy podać funckję, której wynikiem jest jedna wartość np. mean, median, sd albo fun.data - należy podać funkcję, której wynikiem jest więcej wartości np. mean_cl_boot i mean_cl_normal policzą średnią i przedział ufności. Należy też dobrać odpowiedni geom: dla jednej wartości np. point albo line, dla większej: linerange, crossbar, pointrange, errorbar. p &lt;- ggplot(data=dane1, aes(x=Szczep, y=pomiar, color=Szczep)) # Wykres tylko z wartością średnią p + stat_summary(fun = &quot;mean&quot;, geom = &quot;point&quot;, size = 3)+ facet_wrap(~ warunki, ncol = 2) # Wykres ze średnią i przedziałem ufności policzonym metodą bootstrap p + stat_summary(fun.data = &quot;mean_cl_boot&quot;)+ facet_wrap(~ warunki, ncol = 2) 4.4.2 Summary z użyciem dplyr Do samodzielnego policzenia średnich możemy wykorzystać pakiet dplyr. Pozwala on m.in. na szybkie tworzenie podsumowań danych ze względu na zmienne np. różne szczepy. Najpierw dane są dzielone na grupy, następnie każda grupa jest poddawana działaniu pewnej funkcji lub kilku funkcji, a wynik jest zapisywany do nowej ramki danych. W pakiecie dplyr pierwszym krokiem jest podział na grupy - group_by i potem przekazania wyniku do funkcji summarize. library(dplyr) summ &lt;- dane1 %&gt;% group_by(Szczep, warunki) %&gt;% summarize(mean = mean(pomiar), odch = sd(pomiar), blad = odch/sqrt(length(pomiar)), lower = mean-blad, upper = mean+blad) ## `summarise()` has grouped output by &#39;Szczep&#39;. You can override using the `.groups` argument. summ ## # A tibble: 6 × 7 ## # Groups: Szczep [3] ## Szczep warunki mean odch blad lower upper ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 1 4.98 0.973 0.0562 4.93 5.04 ## 2 A 2 3.96 0.748 0.0432 3.92 4.00 ## 3 B 1 6.02 1.43 0.0828 5.93 6.10 ## 4 B 2 6.07 1.13 0.0654 6.00 6.13 ## 5 C 1 5.96 1.85 0.107 5.85 6.07 ## 6 C 2 8.08 3.40 0.196 7.89 8.28 p &lt;- ggplot(data = summ, aes(x = Szczep, y = mean, ymin = lower, ymax = upper, color = Szczep)) + facet_wrap(~ warunki, ncol = 2) # Wykres ze średnią i błędem standardowym p + geom_pointrange() p + geom_crossbar(width = 0.5) p + geom_errorbar(width = 0.5, color = &quot;black&quot;) + geom_point() # Z wykresem przedstawiającym średnie można postąpić tak samo jak z boxplotem p &lt;- ggplot(data = summ, aes(x = Szczep, y = mean, ymin = lower, ymax = upper, color=factor(warunki))) p + geom_crossbar(width = 0.5, position = &quot;dodge&quot;) # Jeżeli średnie połączymy za pomocą linii otrzymamy wykres interakcji opisany w dalszej części p &lt;- ggplot(data = summ, aes(x = Szczep, y = mean, color = factor(warunki))) p + geom_point() + geom_line(aes(group = warunki)) 4.4.3 Słupki błędów W publikacja często spotyka się wykresy słupkowe z dodanym słupkiem błędu. Podobny efekt w ggplot2 można uzyskać przy pomocy geom_errorbar albo geom_linerange. Należy w aes podać dolną i górną granicę słupka. Jednak jeżeli słupki pochodzą np. z trzech powtórzeń danego eksperymentu to może lepiej byłoby je zaznaczyć w postaci kropek z przedziałem ufności niż rysować słupki. Wartość średnią i ewentualny błąd standardowy albo przedział ufności możemy policzyć sami albo wykorzystać w tym celu stat_summary. # Przykładowe dane dane &lt;- data.frame(kontrola = c(3,7,6), eksp_1 = c(5,9,7.5), eksp_2 = c(3,1,6), eksp_3 = c(10,11,8), eksp_4 = c(1,12,4)) # przechodzimy do formatu tidy library(tidyr) dane %&gt;% pivot_longer(cols = everything(), names_to = &#39;key&#39;, values_to = &#39;value&#39;) -&gt; dane head(dane) ## # A tibble: 6 × 2 ## key value ## &lt;chr&gt; &lt;dbl&gt; ## 1 kontrola 3 ## 2 eksp_1 5 ## 3 eksp_2 3 ## 4 eksp_3 10 ## 5 eksp_4 1 ## 6 kontrola 7 # liczymy średnią i np. błąd standardowy podsumowanie &lt;- dane %&gt;% group_by(key) %&gt;% summarize( srednia = mean(value), odchylenie = sd(value), dolny = srednia-(odchylenie/sqrt(length(value))), gorny = srednia+(odchylenie/sqrt(length(value)))) # Wykres słupkowy z zaznaczonym błędem standardowym p &lt;- ggplot(data = podsumowanie) p + geom_col(aes(x = key, y = srednia), fill = &quot;lightblue3&quot;)+ geom_errorbar(aes(ymin = dolny, ymax = gorny, x = key), width = 0.2) p + geom_col(aes(x = key, y = srednia), fill = &quot;lightblue3&quot;)+ geom_linerange(aes(ymin = dolny, ymax = gorny, x = key)) # Wykres punktowy wyników z zaznaczonym błędem standardowym p + geom_point(data = dane, aes(x = key, y = value))+ geom_pointrange(aes(x = key, ymin = dolny, ymax = gorny, y = srednia), col = &quot;red2&quot;) p + geom_point(data = dane, aes(x = key, y = value))+ geom_crossbar(aes(x = key, ymin = dolny, ymax = gorny, y = srednia), col = &quot;red2&quot;, width = 0.25) p + geom_point(data = dane, aes(x = key, y = value))+ geom_errorbar(aes(x = key, ymin = dolny, ymax = gorny, y = srednia), col = &quot;red2&quot;, width = 0.25) 4.5 Wykres punktowy i liniowy Zacznijmy od pojedynczego pomiaru szczepu A z dane3 Dla geom_point albo geom_line konieczne jest w aes podanie x i y. dane3_1 &lt;- filter(dane3, Szczep == &quot;A&quot; , powt == &quot;1&quot;) p &lt;- ggplot(data = dane3_1, aes(x = czas, y = pomiar)) p + geom_point() p + geom_line() 4.5.1 Dopasowanie linii trendu do wykresu punktowego Zamiast rysować linię, możemy dopasować do wyników linię trendu (może być też inna niż liniowa np. logarytmiczna, kwadratowa, ograniczają nas tylko umiejętności pisania formuł w R ;)). Dopasowanie wykona stat_smooth. Domyślnie dopasuje linię do danych korzystając z własnego algorytmu (loess - lokalne wygładzanie wielomianami niskich stopni ;)), który ma za zadanie uzyskać jak najlepsze dopasowanie do danych, zaznaczy również przedział ufności. Możemy narzucić własną metodę i formułę. # metoda loess p + geom_point() + stat_smooth() ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; # metoda lm - dopasowanie do linii prostej p + geom_point() + stat_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; # metoda lm z podaną formułą p + geom_point() + stat_smooth(method = &quot;lm&quot;, formula = y~log(x))+ stat_smooth(method = &quot;lm&quot;, color = &quot;red&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Sprawdzenie dopasowania można wykonać funkcją lm. Jej summary podaje wartośc R^2, istotność, parametry wzoru(coefficients). summary(lm(pomiar~czas, data=dane3_1)) ## ## Call: ## lm(formula = pomiar ~ czas, data = dane3_1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.094113 -0.014337 0.009274 0.023692 0.055815 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.352e-02 4.631e-03 13.72 &lt;2e-16 *** ## czas 1.027e-02 7.962e-05 128.97 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.0325 on 198 degrees of freedom ## Multiple R-squared: 0.9882, Adjusted R-squared: 0.9882 ## F-statistic: 1.663e+04 on 1 and 198 DF, p-value: &lt; 2.2e-16 # dodanie tekstu do wykresu np. równanie opisujące linię trendu p + geom_point() + stat_smooth(method = &quot;lm&quot;, color = &quot;red&quot;)+ geom_text(data = NULL, x = 50, y = 0.2, label = &quot;y = ax + b&quot;, size = 5) ## `geom_smooth()` using formula &#39;y ~ x&#39; Możemy zastosować stat_smooth dla wszystkich danych. geom_point można rozróżniać pod względem: color, shape, size, a geom_line pod względem: color i linetype. p &lt;- ggplot(data=dane3, aes(x = czas, y = pomiar, color = Szczep)) p + geom_point(size = 0.75) + stat_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; p + geom_point(size = 0.75) + stat_smooth(method = &quot;lm&quot;) + facet_wrap(~Szczep) ## `geom_smooth()` using formula &#39;y ~ x&#39; Do przedstawienia takich danych można też użyć boxplot. p &lt;- ggplot(data=dane3, aes(x=czas, group = plyr::round_any(czas, 10, floor), y=pomiar)) p + geom_boxplot()+facet_wrap(~Szczep) 4.5.2 Jak poradzić sobie z nadmiarem punktów na wykresie (overplotting)? Jednym z problemów podczas stosowania wykresów punktowych może być zbyt duża liczba punktów powodująca zacieranie się informacji. W ggplot2 możemy skorzystać z kilku sposobów poradzenia sobie z “overplotting.” W przypadku danych ciągłych można wykorzystać parametr alpha pozwalający na ustawienie półprzezroczystych punktów albo wykorzystać punkty niewypełnione w środku - shape = 1:14. Innym sposobem może być wykorzystanie geom_density2d, który wylicza gęstość w układzie dwuwymiarowym i zaznacza liniami na wykresie albo geom_bin2d , który pozwala zrobić dwuwymiarowy histogram, możliwa kotrola binwidth (trzeba podać wektor dwóch wartości). Dla danych dyskretnych pomóc może wykorzystanie position=\"jitter\", która pozwala losowo rozrzucić punkty albo zastosowanie parametru alpha oraz stat_sum - wielkość punktów zależy od ilości nakładających się punktów. # przykładowe dane ciągłe dane &lt;- data.frame(x = rnorm(4000), y = rnorm(4000)) p &lt;- ggplot(dane, aes(x = x,y = y)) p + geom_point() # zastosowanie alpha p + geom_point(alpha = 0.25) # puste punkty p + geom_point(shape = 1) # geom_density2d albo geom_bin2d() p + geom_point()+geom_density2d(color = &quot;red2&quot;) p + geom_bin2d() # można również użyć stat_density2d z innym geomem niż linia p + stat_density2d(geom = &quot;polygon&quot;, aes(fill = ..level..)) # linie widoczne na wykresach są wynikiem konwersji do pdf, nie będzie ich na wykresach zapisanych np. w formacie .tiff p + stat_density2d(geom = &quot;tile&quot;, contour = FALSE, aes(fill = ..density..)) p + stat_density2d(geom = &quot;tile&quot;, contour = FALSE, aes(fill = ..density..))+ scale_fill_gradient(low = &quot;lightyellow&quot;, high = &quot;darkgreen&quot;) p + stat_density2d(geom = &quot;tile&quot;, contour = FALSE, aes(fill = ..density..))+ scale_fill_viridis_c() p + stat_density2d(geom = &quot;tile&quot;, contour = FALSE, aes(alpha = ..density..)) # zamiast kwadratów można użyć sześciokątów, wymaga zainstalowanie pakietu hexbin library(hexbin) p + stat_binhex() # dane dyskretne dane &lt;- round(2*dane) p &lt;- ggplot(dane, aes(x = x,y = y)) p + geom_point() p + geom_point(alpha = 0.05) # wykorzystanie position = &quot;jitter&quot; i alpha p + geom_point(position = &quot;jitter&quot;, alpha = 0.3) # z wykorzystaniem stat_sum p + stat_sum() # czasem pomóc może też zmiana skali na logarytmiczną dane &lt;- data.frame(x = rlnorm(1000), y = rlnorm(1000)) p &lt;- ggplot(dane, aes(x = x,y = y)) p + geom_point() p + geom_point()+scale_y_log10()+scale_x_log10() 4.5.3 Wykres wstążka (ribbon) Użycie geom_ribbon wymaga wstępnego podsumowania danych np. przy użyciu dplyr - analogicznie jak dane1. W tym wypadku zmiennymi, pod względem których będziemy dzielić dane na grupy będą szczep i czas. Półprzezroczystą wstążkę uzyskujemy dzięki parametrowi alpha. library(dplyr) summ &lt;- dane3 %&gt;% group_by(Szczep, czas) %&gt;% summarize(mean = mean(pomiar), sd = sd(pomiar), blad = sd/sqrt(length(pomiar)), lower = mean-blad, upper = mean+blad) ## `summarise()` has grouped output by &#39;Szczep&#39;. You can override using the `.groups` argument. p &lt;- ggplot(data = summ, aes(x = czas, y = mean, color = Szczep, fill = Szczep)) p + geom_line() + geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.25) 4.6 Kolory, osie, panele 4.6.1 Porównywanie - fill, color, shape Porównanie kilku szczepów można zrobić w ten sam sposób, wybierając w aes - fill=Szczep albo color=Szczep (w zależności od geomu, fill pasuje do histogram i density, color do density, line, point, boxplot itd.) W histogramie domyślnie dostaniemy słupki ustawione jeden na drugim, jeżeli chcemy słupki ustawione obok siebie należy ustawić parametr position=\"dodge\". W przypadku boxplot dla kilku cech można pod x podstawić Szczep - otrzymamy wykres zawierający po jednym boxplocie dla jednego szczepu. Wybieram dane tylko dla warunków 1. dane1_2 &lt;- dane1 %&gt;% filter(warunki == 1) p &lt;- ggplot(data = dane1_2, aes(x = pomiar)) # Histogram dla trzech szczepów p + geom_histogram(aes(fill = Szczep, y = ..density..), binwidth = 0.5, position=&quot;dodge&quot;) # Gęstość dla trzech szczepów rozróżniona przez color p + geom_density(aes(color = Szczep)) # Gęstość rozróżniona przez fill, półprzezroczystość uzyskujemy parametrem alpha p + geom_density(aes(fill = Szczep), alpha = 0.25, size = 0.75) # Histogramy nałożone na siebie - wymaga ustawienia position = &quot;identity&quot; p &lt;- ggplot(data=dane1_2, aes(x = pomiar)) p + geom_histogram(aes(y = ..density.., fill = Szczep), binwidth = 0.75, alpha = 0.45, position = &quot;identity&quot;) # Histogram &quot;back to back&quot; wymaga ustawienia w drugim geom_histogram ujemnego y dane1_3 &lt;- dane1 %&gt;% filter(Szczep == &quot;B&quot;, warunki == 1) p &lt;- ggplot(data = dane1_1, aes(x = pomiar)) p &lt;- p + geom_histogram(aes(y = ..density.., fill = &quot;dodgerblue3&quot;), binwidth = 0.75)+ geom_histogram(data = dane1_3, aes(x = pomiar, y = -..density.., fill = &quot;coral2&quot;), binwidth = 0.75)+ scale_fill_manual(name = &quot;Szczep&quot;, values = c(&quot;coral2&quot; = &quot;coral2&quot;, &quot;dodgerblue3&quot; = &quot;dodgerblue3&quot;), labels = c(&quot;B&quot;,&quot;A&quot;)) p p + coord_flip() # Boxplot dla każdego szczepu p &lt;- ggplot(data = dane1_2, aes(x = Szczep, y = pomiar)) p + geom_boxplot() # Boxploty też mogą być kolorowe ;) p + geom_boxplot(aes(color = Szczep)) 4.6.2 Zmiana skali kolorów Możemy zmienić domyślne kolory wykresu korzystając z funkcji scale_colour\\fill_sth. Rodzaj funkcji zależy od rodzaju danych - ilościowe albo jakościowe. Dla danych jakościowych można użyć: scale_color_grey - odcienie szarości, scale_colour_brewer - zawiera zestawy kolorów ze strony Color Brewer, scale_color_viridis_d - zawiera palety viridis, scale_color_hue - pozwala na wybranie kolorów korzystając z palety HCL. Można też ustawić własny zestaw kolorów korzystając z nazw kolorów R albo np. przez RGB, korzystając z scale_colour_manual Dla danych ilościowych można wybrać: scale_color_gradient - gradient między dwoma kolorami, scale_color_gradient - gradient pomiędzy 3 kolorami, scale_color_gradientn - gradient pomiędzy dowolną liczbą kolorów albo scale_color_viridis_c # Zmienne jakościowe # Odcienie szarości p &lt;- ggplot(data = dane1_2, aes(x = pomiar)) p + geom_histogram(aes(fill = Szczep, y = ..density..), binwidth = 0.5)+ facet_wrap(~Szczep) + scale_fill_grey() # można wybrać początek i koniec skali p + geom_histogram(aes(fill = Szczep, y = ..density..), binwidth = 0.5)+ facet_wrap(~Szczep) + scale_fill_grey(start = 0.1, end = 0.6) # skala ColorBrewer library(RColorBrewer) display.brewer.all() # z użyciem ColorBrewer p &lt;- ggplot(data = dane1_2, aes(x = pomiar)) p + geom_histogram(aes(fill = Szczep, y = ..density..), binwidth = 0.5)+ facet_wrap(~Szczep) + scale_fill_brewer() p + geom_histogram(aes(fill = Szczep, y = ..density..), binwidth = 0.5)+ facet_wrap(~Szczep) + scale_fill_brewer(palette = &quot;Set1&quot;) # z użyciem viridis, argument option przyjmuje wartości od A do H p + geom_histogram(aes(fill = Szczep, y = ..density..), binwidth = 0.5)+ facet_wrap(~Szczep) + scale_fill_viridis_d(option = &#39;C&#39;) # zakres palety można modyfikować przy pomocy argumentów begin i end p + geom_histogram(aes(fill = Szczep, y = ..density..), binwidth = 0.5)+ facet_wrap(~Szczep) + scale_fill_viridis_d(option = &#39;C&#39;, begin = 0.4) # skala z użyciem palety HCL - ustawiamy trzy argumenty: h(zakres barw), c(intensywność) i l(jasność) p + geom_histogram(aes(fill = Szczep, y = ..density..), binwidth = 0.5)+ facet_wrap(~Szczep) + scale_fill_hue(h = c(160,320)) p + geom_histogram(aes(fill = Szczep, y = ..density..), binwidth = 0.5)+ facet_wrap(~Szczep) + scale_fill_hue(c = 200) p + geom_histogram(aes(fill = Szczep, y = ..density..), binwidth = 0.5)+ facet_wrap(~Szczep) + scale_fill_hue(l = 85) # skala manualna p + geom_histogram(aes(fill = Szczep, y = ..density..), binwidth = 0.5)+ facet_wrap(~Szczep) + scale_fill_manual(values = c(&quot;forestgreen&quot;, &quot;dodgerblue&quot;, &quot;coral&quot;)) # Zmienne ilościowe # domyślny gradient p &lt;- ggplot(subset(dane1_2, pomiar &lt; 10)) p &lt;- p + geom_jitter(aes(x = Szczep, y = pomiar, color = pomiar), size = 3) # dwa kolory p + scale_color_gradient(low = &quot;darkgreen&quot;, high = &quot;gold&quot;) # trzy kolory - domyślnie założy, że wartość środkowa to zero, jeżeli jest inaczej to trzeba to podać w midpoint p + scale_color_gradient2(low = &quot;darkgreen&quot;, mid = &quot;coral&quot;, high = &quot;gold&quot;, midpoint = 6) # więcej kolorów p + scale_color_gradientn(colours = c(&quot;green&quot;, &quot;red&quot;, &quot;yellow&quot;, &quot;blue&quot;)) # ColorBrewer p + scale_color_distiller(palette = 4) # viridis p + scale_color_viridis_c(option = &#39;A&#39;) p + scale_color_viridis_c(option = &#39;D&#39;) p + scale_color_viridis_c(option = &#39;H&#39;) Analogicznie do kolorów można ustawiać skale dotyczące kształtu punktów, stylu linii itp. 4.6.3 Podział wykresu na panele Innym sposobem na rozróżnianie danych jest użycie paneli (facet). Dzielimy wykres na części pod względem zmiennej np. Szczepu używając facet_wrap albo facet_grid facet_grid - rozmieści wykresy w tabeli według jednej lub dwóch zmiennych podanych w formule np. zmienna1 ~ zmienna2 facet_wrap - stworzy “wstążkę” wykresów, końcową liczbę kolumn/wiersz można ustawić argumentami ncol/nrow. W formule po + można dodawać kolejne zmienne np. ~ zmienna1 + zmienna2 p &lt;- ggplot(data = dane1_2, aes(x = pomiar)) p + geom_histogram(aes(y = ..density..), binwidth = 0.5, position = &quot;dodge&quot;)+ facet_wrap(~Szczep, ncol = 1) p + geom_density(aes(color = Szczep)) + facet_wrap(~Szczep, ncol = 1) Oba sposoby można ze sobą dowolnie łączyć. Analizujemy dane pod względem szczepu i warunków. p &lt;- ggplot(data = dane1, aes(x = pomiar)) p + geom_histogram(binwidth = 0.5, aes(fill = factor(warunki)), position = &quot;dodge&quot;)+ facet_wrap(~Szczep, ncol = 1) p + geom_density(aes(color = Szczep)) + facet_wrap(~ warunki, ncol = 2) # Histogram podzielony pod względem szczepu i warunków - facet_grid p + geom_histogram(binwidth = 1) + facet_grid(Szczep ~ warunki) # Podobny efekt do facet_frid można osiągnąć stosując facet_wrap z więcej niż jednym warunkiem # Kolejne warunki dodaje się znakiem + p + geom_histogram(binwidth = 1) + facet_wrap(~Szczep + warunki, ncol = 2) # Osie nie muszą być jednakowe dla wszystkich części p + geom_histogram(binwidth = 1) + facet_grid(Szczep ~ warunki, scales = &quot;free&quot;) # Dzielić na części dzięki facet można każdy typ wykresu p &lt;- ggplot(data = dane1, aes(x = Szczep, y = pomiar)) p + geom_boxplot(aes(color = Szczep)) + facet_wrap(~ warunki) # Boxploty można również rozmiescić według jednego czynnika, a pokolorować według drugiego p + geom_boxplot(aes(color = factor(warunki))) 4.6.4 Zmiana skali, osi, obracanie wykresu ggplot2 domyślnie dobiera takie parametry osi, żeby zmieściły się wszystkie dane, ale można je zmieniać używając scale_x_continuous albo scale_y_continuous. Jeżeli chcemy tylko zmienić limity osi można to zrobić funkcją xlim i ylim. Trzeba pamiętać, że po zmianie limitów osi najpierw zostaną usunięte wartości, które się nie mieszczą, a potem policzone statystyki, więc takie wykresy jak geom_boxplot, stat_smooth, stat_summary i inne mogą ulec zmianie. Jeżeli chcemy tego uniknąć należy zamiast osi zmieniać układ współrzędnych - coord_cartesian(xlim, ylim). Przy ich pomocy możemy zmienić np. parametry: * limits - miejsce startu i końca osi np limits = c(1,10) * name - nazwa osi * breaks - miejsca “tick marks” * labels - nazwy “tick marks” Podstawowe transformacje osi to scale_y_log10, scale_y_reverse, scale_y_sqrt. Oś % - należy wpisać labels=percent w scale oraz załadować pakiet scales. Jeżeli chcemy obrócić wykres o 90 stopni możemy użyć funkcji coord_flip. # Zmiana osi na przykładzie boxplot p &lt;- ggplot(data = dane1_2, aes(x = Szczep, y = pomiar)) p &lt;- p + geom_boxplot() # Ustawienie startu i końca osi oraz miejsc podziału p + scale_y_continuous(limits = c(0,15), breaks = 0:15) # Miejsca podziału nie muszą być w równych odstępach i mogą być dowolnie nazwane p + scale_y_continuous(limits = c(0,15), breaks = c(1,4,7,15), labels = c(&quot;mało&quot;, &quot;lepiej&quot;, &quot;ok&quot;, &quot;za dużo&quot;), name = &quot;Coś&quot;) # Wykres obrócony p + scale_y_continuous(limits = c(0,15), breaks = c(1,4,7,15), labels = c(&quot;mało&quot;, &quot;lepiej&quot;, &quot;ok&quot;, &quot;za dużo&quot;), name=&quot;Coś&quot;) + coord_flip() # Skala logarytmiczna p + scale_y_log10(limits = c(1,15), breaks = 1:15) # Wykres &quot;do góry nogami&quot; p + scale_y_reverse() library(scales) # Oś procentowa p &lt;- ggplot(data = dane1_1, aes(x = pomiar)) p + geom_histogram(binwidth = 0.5, aes(y = ((..count..)/sum(..count..))))+ scale_y_continuous(labels = percent, name = &quot;Procent komórek&quot;) 4.7 Motyw (theme) W pakiecie ggplot2 jest dostępnych kilka różnych motywów. Domyślnie ustawiony jest theme_grey, inne dostępne to theme_bw, theme_minimal, theme_classic, theme_linedraw, theme_light. W pakiecie ggthemes znajdują się dodatkowe wersje motywów, nawet (o zgrozo) theme_excel ;) Inny pakiet zawierający gotowe motywy to ggthemr - można go pobrać z GitHub. Tytuł do wykresu możemy dodać korzystając z funkcji ggtitle. Nazwy osi też można szybko zmienić przy pomocy xlab i ylab. p &lt;- ggplot(data = dane1, aes(x = pomiar)) p &lt;- p + geom_histogram(binwidth = 0.5, aes(fill = factor(warunki)), position = &quot;dodge&quot;)+ facet_wrap(~Szczep, ncol = 1) p p + theme_bw() p + theme_classic() p + theme_minimal() p + ggtitle(&quot;Tytuł&quot;) + xlab(&quot;Rodzaj pomiaru&quot;) Legendę wykresu można modyfikować przy pomocy guide_legend wewnątrz funkcji scale_fill_discrete , scale_colour_discrete itp. Dostępne parametry to m.in. title, title.position, label.position, direction, nrow i ncol legendy. Modyfikacje są możliwe też bezpośrednio w funkcji theme albo samodzielnie ustawiając przez scale_color_manual. p + scale_fill_discrete(guide = guide_legend(title = &quot;Warunki&quot;, title.position = &quot;left&quot;, label.position = &quot;bottom&quot;, ncol = 2)) Można również modyfikować osobno każdy element wykresu np. czcionkę, kolor, linie, tło itd. przy pomocy funkcji theme, dużo przykładów znajduję się na stronie. Można modyfikować jednocześnie wszystkie elementy danego rodzaju np. tekst przy pomocy text = element_text() albo pojedyncze części wykresu np. tytuł - plot.title=element_text(). p + theme(text = element_text(size = 22, face = &quot;italic&quot;, color = &quot;darkblue&quot;)) p + ggtitle(&quot;Tytuł wykresu&quot;)+theme(plot.title = element_text(color = &quot;red&quot;, face = &quot;bold&quot;, size = 30, angle = 350, hjust = 0.2, vjust = 0.8)) p + theme(panel.background = element_rect(fill = &quot;lightyellow&quot;), panel.grid.major = element_line(color = &quot;snow4&quot;), strip.background = element_rect(fill = &quot;lightblue3&quot;)) Jeżeli chcemy przygotować kilka pasujących do siebie wykresów możemy zapisać swój motyw i potem dodawać go do kolejnych wykresów. motyw &lt;- theme(panel.background = element_rect(fill = &quot;lightyellow&quot;), panel.grid.major = element_line(color = &quot;snow4&quot;), strip.background = element_rect(fill = &quot;lightblue3&quot;)) p p + motyw 4.8 Różne 4.8.1 Łączenie wykresów Pakiet ggplot2 jest oparty o system wyświetlania kontrolowany przez pakiet grid (inny niż grafika z podstawowego R). Korzystając z funkcji viewport można z dużą dokładnością rozmieścić kilka wykresów różnych rozmiarów obok siebie, jeden na drugim itp. W funkcji viewport ustawiamy parametry width i height oznaczające wymiary wykresu. Wykres zajmujący całą powierzchnię ma wymiary 1x1 oraz x i y oznaczające współrzędne środka wykresu np. x=0.5, y=0.5 da wykres umiejscowiony na samym środku. Dużo łatwiejszym sposobem jest wykorzystanie pakietu patchwork. Pozwala on na ułożenie wykresów na jednej stronie tlyko przy użyciu +, | i /. Można też dokładnie ustalać rozmieszczenie wykresów, więcej na stronie autora pakietu # Przypisujemy wykresy do zmiennych p1 &lt;- ggplot(data=dane1, aes(x=pomiar)) p1 &lt;- p1 + geom_density(aes(color=Szczep))+facet_wrap(~warunki, ncol=2) p2 &lt;- ggplot(data=summ, aes(x=czas, y=mean, color=Szczep, fill=Szczep)) p2 &lt;- p2 + geom_line()+geom_ribbon(aes(ymin=lower, ymax=upper),alpha=0.25) p3 &lt;- ggplot(mtcars) + geom_boxplot(aes(gear, disp, group = gear)) # z wykorzytsaniem patchwork library(patchwork) p1 + p2 + p3 p1 | p2 / p3 (p1 | p2 )/ p3 (p1 | p2 )/ p3 + plot_layout(guides = &#39;collect&#39;) layout &lt;- &quot; ##BBBB AACCCC AACCCC &quot; p1 + p2 + p3 + plot_layout(design = layout) # Z wykorzystaniem pakietu grid library(grid) p1 &lt;- p1 + theme(text=element_text(size=10)) p2 &lt;- p2 + theme(text=element_text(size=10), legend.position=&quot;bottom&quot;) # Ustawiamy parametry viewportóW vp1 &lt;- viewport(width=1, height=0.5, x=0.5, y=0.75) vp2 &lt;- viewport(width=0.4, height=0.5, x=0.2, y=0.25) vp3 &lt;- viewport(width=0.6, height=0.5, x=0.7, y=0.25) # Wyświetlamy wykresy w ospowiednich viewportach print(p1, vp=vp1) print(p2, vp=vp2) print(p3, vp=vp3) 4.8.2 Ten sam wykres różne dane Istnieje kilka sposobów na przygotowanie kilku takich samych wykresów, różniących się jedynie danymi. Można oczywiście ręcznie podmienić wartość parametru data na inny albo skorzystać z wbudowanego w pakiet ggplot2 operatora - %+%. Alternatywą jest też napisanie własnej funkcji przygotowującej konkretny wykres. Zaletą tego rozwiązania jest możliwość wpisania do funkcji odpowiednich argumentów dostosowujących wykres do konkretnej sytuacji. # Przykładowe zestawy danych a &lt;- data.frame(x = rnorm(1000)) b &lt;- data.frame(x = rlnorm(1000)) c &lt;- data.frame(x = runif(1000, 0, 5)) # Przygotujemy wykres składajacy się z kilku elementów dla danych a p &lt;- ggplot(data = a, aes(x = x)) p &lt;- p + geom_histogram(binwidth = 0.25, fill = &quot;blue4&quot;, aes(y = (..count../sum(..count..))))+ scale_y_continuous(labels = percent, name = &quot;Procent&quot;)+ xlab(&quot;Wartość&quot;)+ ggtitle(&quot;Przykładowy rozkład&quot;)+ theme(panel.background=element_rect(fill = &quot;white&quot;), text = element_text(size = 14), axis.text = element_text(color = &quot;red4&quot;)) p # taki sam wykres dla danych b p %+% b # i c ;) p %+% c 4.9 Rozszeżenia ggplot2 W ostatnich latatach powstało bardzo wiele pakietów rozbudowujących możliwości ggplot2. Część z nich została już wspomniana wcześniej np. ggbeeswarm lub patchwork. Tutaj znajdą się inne, które również mogą okazać się przydatne. Większość dobrze udokumentowanych pakietów można znaleźć na stronie ggplot2 extensions - gallery. 4.9.1 Pakiet GGally Pakiet GGally stanowi rozszeżenie ggplot2, zawiera kilka szablonóe i pozwala na stworzenie wykresów niedostępnych w wersji podstawowej np. macierz korelacji, wykres pokazujący sieć albo macierz wykresów dla ramki danych. 4.9.1.1 Macierz wykresów - ggpairs Funkcja ggpairs pozwala na szybką analizę danych. Jej argumentem jest ramka danych i dla każdej pary zmiennych zostanie narysowany wykres pozkazujący zalezność pomiędzy nimi. Wykresy są inne w zależności od rodzaju zmiennych - liczbowe lub kategoryczne. Dla pary zmiennych liczbowych zostanie narysowany wykres rozrzutu i obliczony współczynnik korelacji. Dla pary mieszanej (liczbowo-kategoryczna) narysuje wykres pudełkowy i histogram, dla dwóch zmiennych kategorycznych wykresy słupkowe. Rodzaje rysowanych wykresów można zmieniać, można też do macierzy dodać własny wykres. dane &lt;- data.frame(liczb_1 = sort(rnorm(300, 2)), liczb_2 = sort(rlnorm(300, 1, 0.5)), kategoria_1 = rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;), each=100), kategoria_2 = sample(c(&quot;Tak&quot;,&quot;Nie&quot;),300, replace=TRUE)) library(GGally) ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 ggpairs(dane) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. # zmiana rodzaju wykresu np. górny panel pokaże wykres gęstości zamiast korelacji # i kropkowy zamiast boxplota ggpairs(dane, upper=list(continuous=&quot;density&quot;, combo=&quot;dot&quot;)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. # wykres pokolorowany według jednej z kategorii ggpairs(dane, mapping = ggplot2::aes(color=kategoria_1)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 4.9.1.2 Macierz korelacji Tworzenie macierzy korelacji jest opisane w dalszej części z wykorzystaniem pakietu corrplot, ale możliwe jest też użycie ggplot2. dane &lt;- data.frame(a=sort(rnorm(100)), b=sort(rnorm(100)), c=rnorm(100), d=rlnorm(100), e=runif(100), f=sort(runif(100)), g=sort(rexp(100), decreasing=TRUE)) ggcorr(dane) # z wpisanymi wartościami korelacji ggcorr(dane, label=TRUE, label_color=&quot;black&quot;, label_round=2) "],["wykresy---pakiet-podstawowy.html", "Chapter 5 Wykresy - pakiet podstawowy 5.1 Histogram - hist 5.2 Wykres rozrzutu - plot 5.3 Wykres pudełkowy - boxplot 5.4 Wykres słupkowy - barplot 5.5 Wykres mozaikowy - mosaicplot 5.6 Wykres kwantylowy - qqPlot 5.7 Diagram venna 5.8 Wykres korelacji - corrplot 5.9 Clustering - analiza skupień", " Chapter 5 Wykresy - pakiet podstawowy W pakiecie podstawowym każdy typ wykresu jest rysowany przy pomocy innej funkcji. Różne funkcje mogą wymagać innego typu danych do działania. Wspólne są natomiast parametry dotyczące wyświetlania i wyglądu wykresu. Często, żeby uzyskać właściwy wygląd osi, legendy musimy ją dodać samodzielnie przy pomocy funkcji legend lub axis. Funkcje pakietu podstawowego przydają się najbardziej, gdy trzeba coś szybko sprawdzić, gdyż wymagają mniej pisania niż analogiczne funkcje ggplot2. Jednakże przygotowanie ładnego wykresu korzystając tylko z pakietu podstawowego jest żmudne. 5.1 Histogram - hist Histogram rysujemy funkcją hist. Należy podać wektor zawierający wartości, które mają zostać zliczone. Najważniejszym parametrem histogramu jest breaks, do którego można podać ilość słupków albo wektor przedziałów. freq = TRUE ozancza że na osi Y znajdą się zliczenie elementów w przydziałach, FALSE oznacza gęstości. Parametry ylim i xlim służą do zmiany startu i zakończenia osi. Przy pomocy tej funkcji nie jest możliwe narysowanie histogramu z więcej niż jednego wektora. Możemy na niego nałożyć krzywą oznaczającą gęstość przy pomocy lines(density(x)). Możemy także nie rysować wykresu, ale otrzymać jego liczbową reprezentację używając plot=FALSE. hist(dane1_1$pomiar) hist(dane1_1$pomiar, freq = FALSE, breaks = 20, col = &quot;lightgreen&quot;, xlim = c(2,8)) lines(density(dane1_1$pomiar), col=&quot;red&quot;) # liczbowy opis histogramu - przedziały zliczenia, gęstości itd. hist(dane1_1$pomiar, plot=FALSE) ## $breaks ## [1] 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5 ## ## $counts ## [1] 6 16 22 49 59 59 39 26 22 2 ## ## $density ## [1] 0.04000000 0.10666667 0.14666667 0.32666667 0.39333333 0.39333333 ## [7] 0.26000000 0.17333333 0.14666667 0.01333333 ## ## $mids ## [1] 2.75 3.25 3.75 4.25 4.75 5.25 5.75 6.25 6.75 7.25 ## ## $xname ## [1] &quot;dane1_1$pomiar&quot; ## ## $equidist ## [1] TRUE ## ## attr(,&quot;class&quot;) ## [1] &quot;histogram&quot; 5.2 Wykres rozrzutu - plot Wykres punktowy albo liniowy możemy otrzymać funkcją plot. Podajemy dwa wektory oznaczające współrzędne na osiach X i Y. Możemy określić typ wykresu type: p - punkty l - linia o - punkty i linia s, S - schodki h - linie trochę jak histogram n - brak Linię trendu możemy dodać wykorzystując funkcje lm i abline (dla zależności liniowych) albo lines, lm i predict (nieliniowe). Używając summary i lm możemy wyświetlić wszystkie informacje dotyczące dopasowania. x &lt;- sort(rnorm(10)) y &lt;- sort(rnorm(10)) plot(x,y) plot(x,y, type = &quot;l&quot;) #posortowane, losowe liczby z rozkładu jednostajnego a &lt;- sort(runif(20))*2 b &lt;- sort(runif(20))*2 plot(a,b) # dopasowujemy prostą zależność b od a i rysujemy na wykresie fit &lt;- lm(b~a) abline(fit, col = &#39;red&#39;) # dane muszą być posortowane żeby działała funkcja lines set.seed(100) x &lt;- sort(rnorm(20)) set.seed(300) y &lt;- sort(rnorm(20)) plot(x,y) # dodajemy liniową linię trendu abline(lm(y~x), col = &quot;red&quot;) # albo dopasowujemy wielomian drugiego stopnia lines(x, predict(lm(y~poly(x, 2, raw = TRUE), data.frame(x = x))), col = &quot;blue&quot;) Więcej informacji na temat dopasowywania modelu do danych w części dotyczącej statystyki :) 5.3 Wykres pudełkowy - boxplot Używamy funkcji boxplot. Możemy podać jeden lub kilka wektorów, które posłużą do rysowania “pudełek” albo podobnie jak w ggplot jeden wektor z wartościami i jeden ze zmiennymi je grupującymi. Wcięcia w boxplotach - notch=TRUE, wcięcia oznaczają przedział ufności dla mediany. Jeżeli wcięcia na siebie nie zachodzą to dwie populacje są od siebie najprawdopodobniej istotnie różne. names podpisy pod pudełkami. # Przykładowe dane x &lt;- rnorm(100) y &lt;- rnorm(100, mean = 2) boxplot(x, y) boxplot(dane1$pomiar ~ dane1$Szczep) 5.4 Wykres słupkowy - barplot Rysowany przy pomocy funkcji barplot. Podajemy wektor albo matrycę wartości oznaczające wysokości słupków. Możemy szybko przygotować takie zliczenia funkcją table. W przypadku więcej niż jednego rodzaju słupków można okreslić czy mają być obok siebie - beside=TRUE, kolory zmieniamy parametrem col. barplot(table(dane2$pomiar)) barplot(table(dane2$pomiar, dane2$Szczep)) barplot(table(dane2$pomiar, dane2$Szczep), beside = TRUE) barplot(table(dane2$pomiar, dane2$Szczep), beside = TRUE, col = c(&quot;coral2&quot;, &quot;green3&quot;, &quot;dodgerblue2&quot;)) 5.5 Wykres mozaikowy - mosaicplot Na tym wykresie liczebności poszczególnych grup są reprezentowane przez pole powierzchni prostokąta. Można go przygotować nawet dla trzech lub więcej różnych zmiennych wyliczeniowych poprzez użycie funkcji table albo formuły. # z funckją table mosaicplot(table(dane2$pomiar, dane2$warunki, dane2$Szczep), col = c(&quot;orange&quot;, &quot;green3&quot;, &quot;white&quot;), ylab = &quot;Warunki&quot;, xlab = &quot;Pomiar&quot;) # z formułą mosaicplot(~pomiar + Szczep + warunki, data = dane2, col = TRUE) 5.6 Wykres kwantylowy - qqPlot Dopasowanie danych do rozkładu normalnego można wizualnie sprawdzić przy pomocy wykresu kwantylowego. Funkcja qqPlot z pakietu car rysuje wykres kwantylowy z zaznaczonymi przedziałami ufności. library(car) ## Loading required package: carData ## ## Attaching package: &#39;car&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## recode # Dane z rozkładu normalnego x &lt;- rnorm(300) # Dane z rozkładu lognormalnego y &lt;- rlnorm(300) qqPlot(x) ## [1] 13 60 qqPlot(y) ## [1] 75 177 5.7 Diagram venna Istnieje wiele różnych funkcji generujących diagramy venna. Funkcja venn z pakietu gplots wydaje się być jedną z łatwiejszych. Jej argumentem musi być lista (tworzona funkcją list - każdy kolejny element listy to może być coś innego: wektor, ramka danych, inna lista itp.). W tym wypadku kolejne elementy listy to wektory zawierające wartości zliczane do diagramu. Trzeba zauważyć, że wielkości obszarów nie odpowiadają liczebności grupy, może być nawet narysowany obszar z liczebnością 0. Można tworzyć diagramy z maksymalnie 5 grup, ale powyżej trzech stają się one trudne do odczytania, wtedy lepszą opcją jest narysowanie Upset plot # generowanie zestawów losowych liter set_1 &lt;- sample(letters, 10) set_2 &lt;- sample(letters, 10) set_3 &lt;- sample(letters, 8) library(gplots) ## ## Attaching package: &#39;gplots&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## lowess venn(list(grupa_1 = set_1, grupa_2 = set_2, grupa_3 = set_3)) Jeżeli chcielibyśmy mieć kolorowe diagramy należałoby użyć funkcji venn.diagram z pakietu VennDiagram. Ta funkcja stara się nie rysować obszarów, w których nic nie ma, efekt jej pracy jest również ładniejszy ;) library(VennDiagram) ## Loading required package: futile.logger ## ## Attaching package: &#39;VennDiagram&#39; ## The following object is masked from &#39;package:car&#39;: ## ## ellipse # Do wyświetlenia wymaga najpierw stworzenia obiektu typu grid grid.newpage() grid.draw(venn.diagram(list(grupa_1 = set_1, grupa_2 = set_2, grupa_3 = set_3), fill = c(&quot;red&quot;, &quot;green&quot;,&quot;yellow&quot;), alpha = c(0.5,0.5,0.5), filename = NULL)) 5.8 Wykres korelacji - corrplot Jeżeli dane zawierają kilka kolumn z różnymi zmiennymi do szybkiego sprawdzenie korelacji między nimi możemy użyć macierzy korelacji. Z ramki danych można ją wyznaczyć funkcją cor, natomiast wykres takiej macierzy możemy zrobic np. przy użyciu funkcji corrplot z pakietu corrplot. # ładujemy dane dotyczące pogody pogoda &lt;- read.delim(&quot;data/pogoda.txt&quot;) # tylko pierwsze cztery kolumny zawierają interesujące informacje colnames(pogoda) ## [1] &quot;ozon&quot; &quot;naswietlenie&quot; &quot;wiatr&quot; &quot;temperatura&quot; &quot;miesiac&quot; ## [6] &quot;dzien&quot; pogoda &lt;- pogoda[,1:4] # dane zawierają brakujące informacje. Możemy je usunąć przy pomocy funkcji complete.cases # zwraca numery wierszy nie zawierających wartości NA pogoda &lt;- pogoda[complete.cases(pogoda),] # przygotowujemy macierz korelacji macierz &lt;- cor(pogoda) macierz ## ozon naswietlenie wiatr temperatura ## ozon 1.0000000 0.3483417 -0.6124966 0.6985414 ## naswietlenie 0.3483417 1.0000000 -0.1271835 0.2940876 ## wiatr -0.6124966 -0.1271835 1.0000000 -0.4971897 ## temperatura 0.6985414 0.2940876 -0.4971897 1.0000000 library(corrplot) ## corrplot 0.90 loaded corrplot(macierz) corrplot(macierz, method = &quot;ellipse&quot;, type = &quot;lower&quot;) 5.9 Clustering - analiza skupień Wykorzystamy funkcję kmeans, która pozwala na grupowanie danych w n-liczbę klasterów. Opiera się na metodzie tzw. klasyfikacji bez nadzoru (unsupervised learning), tak aby uzyskać minimalną wariancję wewnątrz danej grupy. Słabością tej metody jest to, że dostaniemy tyle grup ile sobie zażyczymy (niekoniecznie naprawdę istniejących), dlatego dobrze jest wypróbować kilka wartości n. # Przygotowujemy dane złożone z dwóch grup x &lt;- c(rnorm(100,1),rnorm(100,3)) y &lt;- c(rnorm(100,1),rnorm(100,3)) plot(x,y) # Łączymy w matrycę - kmeans działa tylko na matrycach xy &lt;- cbind(x,y) # Przeprowadzamy podział na grupy clu &lt;- kmeans(xy, centers=2) clu ## K-means clustering with 2 clusters of sizes 110, 90 ## ## Cluster means: ## x y ## 1 0.9665061 1.039814 ## 2 3.2469251 3.422692 ## ## Clustering vector: ## [1] 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 ## [112] 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 ## [149] 2 2 1 2 1 1 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 2 1 2 2 2 ## [186] 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 ## ## Within cluster sum of squares by cluster: ## [1] 201.2877 178.5173 ## (between_SS / total_SS = 58.6 %) ## ## Available components: ## ## [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; &quot;tot.withinss&quot; ## [6] &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; &quot;ifault&quot; # możemy sprawdzić dopasowanie - wiemy jakie były grupy test &lt;- rep(c(2,1), each=100) ok &lt;- sum(test == clu$cluster) ok/length(test) ## [1] 0.07 # Rysujemy ponownie wykres pokolorowany według wyznaczonych grup plot(xy, col=clu$cluster) # Dodajemy centra każdej z grup points(clu$centers, col=1:2, pch=8, cex=2) # Powtarzamy, ale z podziałem na 4 grupy # Dane zawierały tylko 2 grupy, ale zostaną podzielone na 4 clu &lt;- kmeans(xy, centers=4) plot(xy, col=clu$cluster) points(clu$centers, col=1:4, pch=8, cex=2) Możemy także grupować dane według wielu zmiennych jendocześnie używając funkcji dist (redukuje wielowymiarowe dane do dwuwymiarowej macierzy odległości) i hclust (podział na grupy). Należy wybrać metodę grupowania, jedne z popularniejszych to ward i complete. Wynik można przedstawić jako dendrogram korzystając ze zwykłej funkcji plot. Poszczególne grupy na wykresie zaznaczamy używając rect.hclust, musimy jedynie podać ilość grup. Wyświetlić grupy możemy za pomocą funkcji cutree, tutaj również niezbędne jest podanie ilości grup. # Wykorzystamy dane spozycie z kursu R, spozycie produktów w różnych krajach spozycie &lt;- read.delim(&quot;data/spozycie.txt&quot;, row.names=1) # Obliczamy macierz odległości d &lt;- dist(spozycie, method=&quot;euclidean&quot;) # Grupujemy kraje CA &lt;- hclust(d, method=&quot;ward.D2&quot;) # Dendrogram plot(CA) rect.hclust(CA, k=5, border=&quot;red&quot;) # Podział krajów na 5 grup grupy &lt;- cutree(CA, k=5) grupy ## Albania Austria Bulgaria Croatia ## 1 2 3 3 ## Czech_Republic Denmark Estonia Finland ## 3 4 3 2 ## France Germany Greece Hungary ## 1 4 1 3 ## Iceland Ireland Italy Latvia ## 4 2 1 3 ## Lithuania Netherlands Norway Poland ## 3 2 4 3 ## Portugal Romania Russian_Federation Slovakia ## 5 1 3 3 ## Slovenia Spain Sweden Switzerland ## 4 5 2 2 ## United_Kingdom ## 4 "],["statystyka.html", "Chapter 6 Statystyka 6.1 Podstawowe statystyki opisowe 6.2 Liczby pseudolosowe 6.3 Podstawowe testy statystyczne 6.4 Modelowanie - czyli jak dopasować linię trendu 6.5 Analiza ANOVA", " Chapter 6 Statystyka W tej części opieram się w dużej mierze na książce “Przewodnik po pakiecie R” P. Biecka oraz na kursie “Środowisko R od podstaw.” Nie ma ona być wprowadzeniem do statystyki jako takiej, ale jedynie pokazaniem jakie funkcje R można wykorzystać do przeprowadzenie często stosowanych analiz statystycznych. Przystępne wprowadzenie do statystyki dla biologów znalazłam na stronie dotyczącej badania C. elegans - wormbook.org. Bardzo mało matematyki i wzorów, za to sporo przykładów, szkoda tylko, że nie ma nic o R ;) 6.1 Podstawowe statystyki opisowe Skrócone podsumowanie danych liczbowych otrzymamy przy użyciu summary - średnia, mediana, wartość min i max, oraz pierwszy i trzeci kwantyl. Podstawowe funkcje służące do opisu danych to: Funkcja Opis Uwagi mean średnia median mediana sd odchylenie standardowe var wariancja min wartość minimalna max wartość maksymalna range zakres danych IQR rozstęp kwartylowy geometric.mean średnia geometryczna weighted.mean średnia ważona musimy podać wektor wag do każdego elementu kurtosis kurtoza pakiet moments skewness skośność pakiet moments mlv moda pakiet modeest quantile wybrane kwantyle należy podać, które kwantyle mają być policzone mad odchylenie medianowe wektor &lt;- rnorm(1000, mean=2) mean(wektor) ## [1] 2.008501 median(wektor) ## [1] 2.00913 range(wektor) ## [1] -1.253799 4.865792 quantile(wektor, c(0.25, 0.4, 0.5, 0.6, 0.75)) ## 25% 40% 50% 60% 75% ## 1.271471 1.725972 2.009130 2.273003 2.737301 library(modeest) mlv(wektor, method = &#39;shorth&#39;) ## [1] 1.868663 6.2 Liczby pseudolosowe Podczas pracy w R często przydaje się możliwość szybkiego wygenerowania liczb z danego rozkładu. Można w ten sposób np. przetestować nową funkcję (również własną ;) ) Wszystkie takie funkcje zaczynają się od r, a ich pierwszy argument to ilość liczb jaka ma zostać wygenerowana. Jeżeli chcemy dwa razy wygenerować takie same liczby należy najpierw ustawić ziarno - set.seed Funkcja opis parametry runif rozkład jednostajny, od 0 do 1 zmiana wartości min i max rozkładu rnorm rozkład normalny, średnia = 0, odchylenie = 1 zmiana mean i sd rlnorm rozkład log-normalny zmiana meanlog i sdlog rexp rozkład wykładniczy zmiana rate rbinom rozkład dwumianowy ustawiamy wielkość (size) i prawdopodobieństwo (prob) a &lt;- rnorm(1000) b &lt;- rlnorm(1000) c &lt;- rexp(1000) d &lt;- runif(1000) par(mfrow=c(2,2)) hist(a, main=&quot;Normalny&quot;) hist(b, main = &quot;Log-Normalny&quot;) hist(c, main = &quot;Wykładniczy&quot;) hist(d, main = &quot;Jenostajny&quot;) par(mfrow=c(1,1)) Możemy też potrzebować wektor losowych wartości z danego zakresu. Służy do tego funckja sample. Pierwszym jej argumentem jest wektor, z którego mają być losowane wartości, drugim ilość elementów do losowania. Można też podać czy losowanie ma być ze zwracaniem (replace=TRUE) i wektor prawdopodobieństwa dla każdego elementu, jeżeli nie mają być takie same. Prawdopodobieństwa muszą sumować się do 1. # Symulacja 200 rzutów kością kosc &lt;- sample(1:6, 200, replace = TRUE) barplot(table(kosc)) # Symulacja nieuczciwej kości kosc2 &lt;- sample(1:6, 200, replace = TRUE, prob = c(0.1, 0.1, 0.1, 0.2, 0.2, 0.3)) barplot(table(kosc2)) 6.3 Podstawowe testy statystyczne 6.3.1 Test t-studenta - weryfikacja równości średnich Można go wykonać dla jednej lub dwóch prób przy pomocy funkcji t.test. Dane muszą być z rozkładu normalnego, ale domyślnie nie muszą mieć równej wariancji. Przy teście dla jednej próby należy podać wartość średniej mu, do której ma zostać przyrównana próba (domyślnie wynosi 0). Przy teście dla dwóch prób możemy również wykonać test dla prób sparowanych - paired=TRUE - sprawdzamy czy różnica między próbami jest różna od 0 np. dane przed i po dodaniu jakiegoś czynnika Domyślnie wykonywany jest test dwustronny, możemy to zmienić parametrem alternative ustawiając \"less\" albo \"greater\". Wynik testu podaje nam kilka wartości: wartość statystyki testowej ilość stopni swobody p-value - minimalny poziom istotności dla którego możemy odrzucić hipotezę zerową. Np. p-value równy 0.05 oznacza, że jeżeli odrzucimy hipotezę zerową istnieje 5% szans, że popełnimy błąd hipoteza alternatywna przedział ufności dla wyliczonej średniej albo różnicy między średnimi średnia z próby Możemy wyświetlić wszystkie te wartości albo jedynie interesujące nas poprzez znak $ np. t.test(x)$p.value. Wynik takiego testu można też przypisać do zmiennej i wykorzystać później. x &lt;- rnorm(100) y &lt;- rnorm(100, mean=1) # test dla jednej próby, porównanie do średnia równej 0 t.test(x) ## ## One Sample t-test ## ## data: x ## t = -0.31224, df = 99, p-value = 0.7555 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -0.2042882 0.1487354 ## sample estimates: ## mean of x ## -0.02777643 t.test(y) ## ## One Sample t-test ## ## data: y ## t = 9.0505, df = 99, p-value = 1.287e-14 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 0.7738458 1.2084402 ## sample estimates: ## mean of x ## 0.991143 # test dla dwóch prób t.test(x,y) ## ## Welch Two Sample t-test ## ## data: x and y ## t = -7.2217, df = 190.02, p-value = 1.203e-11 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.2972245 -0.7406144 ## sample estimates: ## mean of x mean of y ## -0.02777643 0.99114303 wynik &lt;- t.test(x,y) wynik$p.value ## [1] 1.203272e-11 wynik$conf.int ## [1] -1.2972245 -0.7406144 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 # test t można przeprowadzić dla większej ilości grup przy pomocy pairwise.t.test, # wartości p zostaną wtedy dostoswane do wielokrotnego powtarzania testu pairwise.t.test(dane1$pomiar, dane1$Szczep) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: dane1$pomiar and dane1$Szczep ## ## A B ## B &lt;2e-16 - ## C &lt;2e-16 &lt;2e-16 ## ## P value adjustment method: holm Jeżeli nie wiemy z jakiego rozkładu pochodzą dane możemy wykorzystać test nieparametryczny - test Wilcoxona wilcox.test, też podaje wartość p. Analogicznie dla t.test istnieje funkcja pairwise.wilcox.test wilcox.test(x,y) ## ## Wilcoxon rank sum test with continuity correction ## ## data: x and y ## W = 2379, p-value = 1.525e-10 ## alternative hypothesis: true location shift is not equal to 0 6.3.2 Test F - weryfikacja równości wariancji Podobny w składni do t.test, wykonujemy funkcją var.test. Również zakładamy, że dane pochodzą z rozkładu normalnego. Zastosowanie go dla danych z innych rozkładów może prowadzić do błędnych wniosków. var.test(x,y) ## ## F test to compare two variances ## ## data: x and y ## F = 0.65984, num df = 99, denom df = 99, p-value = 0.0398 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.4439686 0.9806782 ## sample estimates: ## ratio of variances ## 0.6598411 z &lt;- rnorm(100, sd=3) var.test(x,z) ## ## F test to compare two variances ## ## data: x and z ## F = 0.076738, num df = 99, denom df = 99, p-value &lt; 2.2e-16 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.05163257 0.11405070 ## sample estimates: ## ratio of variances ## 0.07673806 6.3.3 Testowanie zgodności z rozkładem normalnym i dopasowywanie parametrów rozkładu Metoda graficzna to wspomniany już wykres kwantylowy (qqPlot). Kilka testów, które można wykorzystać znajduje się w pakiecie nortest np. shapiro.test, cvm.test. Test Shapiro-Wilka należy do bardziej popularnych, liczba obserwacji powinna mieścić się w zakresie od 3 do 5000. x &lt;- rnorm(500) y &lt;- rlnorm(500, sdlog = 0.5) # histogram i wykres kwantylowy dla danych x i y par(mfrow = c(2,2)) hist(x) hist(y) qqPlot(x) ## [1] 205 237 qqPlot(y) ## [1] 221 99 par(mfrow = c(1,1)) # test Shapiro-Wilka do sprawdzania zgodności z rozkładem normalnym shapiro.test(x) ## ## Shapiro-Wilk normality test ## ## data: x ## W = 0.99823, p-value = 0.8944 shapiro.test(y) ## ## Shapiro-Wilk normality test ## ## data: y ## W = 0.9017, p-value &lt; 2.2e-16 Do sprawdzenie zgodności z zadanym rozkładem możemy wykorzystać test Kołmogorowa-Smirnowa - ks.test. Do funkcji należy podać wektor obserwacji oraz albo drugi wektor obserwacji (sparwdzamy czy pochodzą z takiego samego rozkładu) albo nazwę funkcji obliczającej dystrybuantę rozkładu np. pnorm (normalny), plnorm (log-normalny), punif (jednostajny). Jeżeli parametry rozkładu różnią się od domyślnych to należy je podać np. mean i sd dla rozkładu normalnego. x &lt;- rnorm(1000) x1 &lt;- rnorm(1000) x2 &lt;- rnorm(1000, mean = 2) y &lt;- rlnorm(1000, sdlog = 0.5) # Sprawdzamy czy obserwacje mają taki sam rozkład ks.test(x,x1) ## ## Two-sample Kolmogorov-Smirnov test ## ## data: x and x1 ## D = 0.037, p-value = 0.5004 ## alternative hypothesis: two-sided ks.test(x,x2) ## ## Two-sample Kolmogorov-Smirnov test ## ## data: x and x2 ## D = 0.671, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided ks.test(x,y) ## ## Two-sample Kolmogorov-Smirnov test ## ## data: x and y ## D = 0.64, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided # Sprawdzamy czy x pochodzi z rozkładu normalnego czy log-normalnego ks.test(x, pnorm) ## ## One-sample Kolmogorov-Smirnov test ## ## data: x ## D = 0.022326, p-value = 0.7012 ## alternative hypothesis: two-sided ks.test(x, plnorm) ## ## One-sample Kolmogorov-Smirnov test ## ## data: x ## D = 0.54985, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided # Jeżeli nie podamy, że średnia x2 równa się 2 otrzymamy błędny wynik ks.test(x2, pnorm) ## ## One-sample Kolmogorov-Smirnov test ## ## data: x2 ## D = 0.68387, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided ks.test(x2, pnorm, mean = 2) ## ## One-sample Kolmogorov-Smirnov test ## ## data: x2 ## D = 0.020089, p-value = 0.8144 ## alternative hypothesis: two-sided # Czy y pasuje do rozkładu normalnego czy log-normalnego ks.test(y, pnorm, sd = 0.5) ## ## One-sample Kolmogorov-Smirnov test ## ## data: y ## D = 0.7663, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided ks.test(y, plnorm, sd = 0.5) ## ## One-sample Kolmogorov-Smirnov test ## ## data: y ## D = 0.02376, p-value = 0.6249 ## alternative hypothesis: two-sided Do oszacowania parametrów rozkładu można wykorzystać funkcję fitdistr z pakietu MASS. Podajemy wektor obserwacji oraz funkcję gęstości rozkładu. Rozpoznawane funkcje to np. \"normal\", \"log-normal\", \"exponential\", \"f\", \"t\" itp. x &lt;- rnorm(1000, mean=20, sd=0.5) library(MASS) ## ## Attaching package: &#39;MASS&#39; ## The following object is masked from &#39;package:patchwork&#39;: ## ## area ## The following object is masked from &#39;package:dplyr&#39;: ## ## select # obliczamy parametry rozkładu normalnego i log-normalnego dla danych x fit &lt;- fitdistr(x, &quot;normal&quot;) fit ## mean sd ## 20.02764577 0.51181914 ## ( 0.01618514) ( 0.01144462) fit2 &lt;- fitdistr(x, &quot;log-normal&quot;) fit2 ## meanlog sdlog ## 2.9967861138 0.0256138133 ## (0.0008099799) (0.0005727423) # sprawdzamy czy dane x faktycznie pochodzą z rozkładu o parametrach obliczonych wyżej ks.test(x, pnorm, fit$estimate[1], fit$estimate[2]) ## ## One-sample Kolmogorov-Smirnov test ## ## data: x ## D = 0.013869, p-value = 0.9906 ## alternative hypothesis: two-sided ks.test(x, pnorm, fit2$estimate[1], fit2$estimate[2]) ## ## One-sample Kolmogorov-Smirnov test ## ## data: x ## D = 1, p-value &lt; 2.2e-16 ## alternative hypothesis: two-sided y &lt;- rlnorm(1000, sdlog = 0.4) fitdistr(y, &quot;log-normal&quot;) ## meanlog sdlog ## -0.010771248 0.395992732 ## ( 0.012522390) ( 0.008854667) 6.3.4 Obliczanie przedziałów ufności dla średniej i błędu standardowego Błąd standardowy obliczamy ze wzoru: \\[SEM= odch/\\sqrt{n}\\]. Pokazuje estymowane odchylenie pomiędzy prawdziwą średnią populacji, a obliczoną dla próby. W R nie ma funkcji liczącej błąd standardowy, ale można takie przeliczenie wykonać samemu albo napisać taką funkcję x &lt;- rnorm(300, mean=10, sd=0.5) mean(x) ## [1] 10.04872 sd(x) ## [1] 0.5133524 SEM &lt;- sd(x)/sqrt(length(x)) cat(&quot;Błąd standardowy wynosi&quot;, SEM) ## Błąd standardowy wynosi 0.02963841 Przedział ufności o istotności 0.95 mówi nam, że prawdopodobieństwo znalezienia estymowanego parametru w tym przedziale wynosi 95%. Przedział ufności dla rozkładu normalnego przy poziomie istotności 0.95 wyliczamy ze wzoru: \\[ci= 1.96*odch/\\sqrt{n}\\] \\[Średnia +/- ci\\] 1.96 to 0.975 kwantyl rozkładu normalnego. Zamiast 1.96 możemy podstawić wartość wyliczoną z rozkładu t przy pomocy: qt(0.975, df) Przy dużej liczebności próby (ok. 300) wyjdzie na to samo. set.seed(120) x &lt;- rnorm(100, mean=3, sd=0.75) (srednia&lt;-round(mean(x),2)) ## [1] 3.02 round(sd(x),2) ## [1] 0.79 ci &lt;- round(1.96*sd(x)/sqrt(length(x)),2) lower &lt;- srednia-ci upper &lt;- srednia+ci cat(&quot;Średnia x wynosi&quot;, srednia, &quot;w przedziale ufności&quot;, lower, upper) ## Średnia x wynosi 3.02 w przedziale ufności 2.86 3.18 ci &lt;- round(qt(0.975, df=(length(x)-1))*sd(x)/sqrt(length(x)),2) lower &lt;- srednia-ci upper &lt;- srednia+ci cat(&quot;Średnia x wynosi&quot;, srednia, &quot;w przedziale ufności&quot;, lower, upper) ## Średnia x wynosi 3.02 w przedziale ufności 2.86 3.18 Przedział ufności dla średniej można też znaleźć w wyniku t.test. 6.3.5 Testowanie korelacji Wartość korelacji zawiera się pomiędzy -1 a 1. 0 oznacza całkowity brak korelacji. Do 0.7 korelację określamy jako silną. Korelację obserwacji z dwóch wektorów albo całej macierzy można obliczyć przy pomocy funkcji cor. Domyślnie obliczona zostanie za pomocą metody Pearsona, można to zmienić na metodę Spearmana - method=\"spearman\". Metoda Spearmana jest mniej wrażliwa na obserwacje odstające. Jeżeli chcemy poznać szczegóły dotyczące korelacji możemy użyć cor.test. Też można wybrać metodę, podaje również wartość p dla korelacji, przedział ufności, ilość stopni swobodi itp. x &lt;- sort(runif(30)) y &lt;- sort(runif(30)) plot(x, y) cor(x, y) ## [1] 0.9866882 cor(x, y, method = &quot;spearman&quot;) ## [1] 1 cor.test(x, y) ## ## Pearson&#39;s product-moment correlation ## ## data: x and y ## t = 32.105, df = 28, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.9719054 0.9937173 ## sample estimates: ## cor ## 0.9866882 # dodajemy wartość bardzo odstającą :) x &lt;- c(x, -100) y &lt;- c(y, 10) plot(x, y) # wartość korelacji wyliczona metodą spearmana zmienia się dużo mniej cor(x, y) ## [1] -0.9816699 cor(x, y, method = &quot;spearman&quot;) ## [1] 0.8125 # wartość odstająca może też dać korelację pearsona tam gdzie jej wcale nie ma # ale korelacja spearmana nie zmieni się tak bardzo x &lt;- sort(runif(30)) y &lt;- runif(30) plot(x, y) cor(x, y) ## [1] 0.1557759 x &lt;- c(x, 10) y &lt;- c(y, 10) plot(x, y) cor(x, y) ## [1] 0.9762845 cor(x, y, method=&quot;spearman&quot;) ## [1] 0.2383065 6.3.6 Test chi-kwadrat - zgodność rozkładu zmiennych jakościowych Służy do weryfikacji zależności pomiędzy dwiema zmiennymi jakościowymi, funkcja chisq.test. Jako argument najlepiej podstawić macierz kontyngencji wyliczoną funkcją table. Poza wartością p można też sprawdzić wartości oczekiwane - wynik$expected. Test chi^2 można wykorzystać też dla wiekszych macierzy. Dla tablic 2x2 można również użyć dokładnego testu Fishera - fisher.test. # Wygenerujemy przykładowe dane - takie same x &lt;- data.frame(jeden = sample(c(&quot;A&quot;,&quot;B&quot;),200, replace = TRUE), dwa = sample(c(&quot;grupa1&quot;,&quot;grupa2&quot;),200, replace = TRUE)) # różne y &lt;- data.frame(jeden = c(sample(c(&quot;A&quot;,&quot;B&quot;),100, replace = TRUE, prob = c(0.4,0.6)), sample(c(&quot;A&quot;,&quot;B&quot;),100, replace = TRUE, prob = c(0.7,0.3))), dwa = rep(c(&quot;grupa1&quot;,&quot;grupa2&quot;),each = 100)) (tabela_x &lt;- table(x)) ## dwa ## jeden grupa1 grupa2 ## A 45 50 ## B 52 53 (tabela_y &lt;- table(y)) ## dwa ## jeden grupa1 grupa2 ## A 40 77 ## B 60 23 chisq.test(tabela_x) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: tabela_x ## X-squared = 0.02654, df = 1, p-value = 0.8706 chisq.test(tabela_y) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: tabela_y ## X-squared = 26.691, df = 1, p-value = 2.387e-07 fisher.test(tabela_x) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: tabela_x ## p-value = 0.7786 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.5068482 1.6595976 ## sample estimates: ## odds ratio ## 0.9177044 fisher.test(tabela_y) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: tabela_y ## p-value = 1.675e-07 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.1025177 0.3835088 ## sample estimates: ## odds ratio ## 0.2009083 Jeżeli chcemy tylko sprawdzić prawdopodobieństwo możemy użyć testu propocji - prop.test # przykładowo czy 785 sukcesów na 1500 prób jest istotnie różne od p=0.5 prop.test(785, 1500, p = 0.5) ## ## 1-sample proportions test with continuity correction ## ## data: 785 out of 1500, null probability 0.5 ## X-squared = 3.174, df = 1, p-value = 0.07482 ## alternative hypothesis: true p is not equal to 0.5 ## 95 percent confidence interval: ## 0.4976972 0.5488486 ## sample estimates: ## p ## 0.5233333 # można też wykonać test proporcji dla większej ilości danych - pairwise.prop.test x &lt;- c(190,475,350,65) n &lt;- c(500,1000,800,250) pairwise.prop.test(x, n, p.adjust.method = &quot;bonferroni&quot;) ## ## Pairwise comparisons using Pairwise comparison of proportions ## ## data: x out of n ## ## 1 2 3 ## 2 0.0035 - - ## 3 0.2803 0.7427 - ## 4 0.0086 7.8e-09 4.8e-06 ## ## P value adjustment method: bonferroni 6.4 Modelowanie - czyli jak dopasować linię trendu Zależność pomiędzy dwiema zmiennymi ilościowymi najłatwiej przedstawić na wykresie rozrzutu. Kolejnym krokiem może być próba dopasowania do danych jakiegoś modelu np. liniowego, ale może być też bardziej złożony np. model wzrostu logistycznego, Michaelisa-Menten itp. 6.4.1 Regresja liniowa Najbardziej popularną funkcją w R do wyznaczania modeli liniowych jest lm. Wymaga jedynie podania formuły opisującej modelowaną przez nas zależność i ramki danych. # Jako przykład wykorzystamy zbiór danych R dotyczący wzrostu drzewek pomarańczowych orange &lt;- Orange head(orange, 3) ## Grouped Data: circumference ~ age | Tree ## Tree age circumference ## 1 1 118 30 ## 2 1 484 58 ## 3 1 664 87 # wykres obwodu drzewa od wieku plot(orange$age, orange$circumference) Formuły zapisujemy korzystając z ~ , np.: * zależność y od x: y~x, * zależność y od x i z: y ~ x + z, * zależność y od x, z i interakcji pomiędzy x i z: y ~ x + z + x:z albo y ~ x * z fit &lt;- lm(circumference~age, data = orange) fit$coefficients ## (Intercept) age ## 17.3996502 0.1067703 summary(fit) ## ## Call: ## lm(formula = circumference ~ age, data = orange) ## ## Residuals: ## Min 1Q Median 3Q Max ## -46.310 -14.946 -0.076 19.697 45.111 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 17.399650 8.622660 2.018 0.0518 . ## age 0.106770 0.008277 12.900 1.93e-14 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 23.74 on 33 degrees of freedom ## Multiple R-squared: 0.8345, Adjusted R-squared: 0.8295 ## F-statistic: 166.4 on 1 and 33 DF, p-value: 1.931e-14 plot(orange$age, orange$circumference) abline(fit, col = &quot;green3&quot;) Jeżeli chcemy jedynie wyznaczyć równanie funkcji liniowej - y = ax + b, wystarczy sprawdzić współczynniki dopasowanego modelu - coefficients. Intercept oznacza miejsce przecięcia z osią Y - współczynnik b, a age to wartość przez którą należy pomnożyć wiek drzewa żeby uzyskać jego obwód. Można powiedzić że według naszego modelu każdego roku obwód drzewa zwiększa się o wartość 0.107 mm. Funkcja summary pozwala zobaczyć wszystkie istotne informacje dotyczące naszego modelu. Pierwsza linijka podsumowania zawiera powtórzenie formuły jaką podaliśmy w funkcji. Następnie mamy podsumowanie wartości residuals - reszt. Są to różnice pomiedzy faktycznymi wartościami a wyznaczonymi ze wzoru. Model jest dobierany tak żeby suma kwadratów reszt była jak najmniejsza. Potem mamy tabelę z wymienionymi wszystkimi współczynnikami modelu. Istotna jest ostatnia kolumna zawierająca wartość p, wartość powyżej 0.05 sugeruje że dana zmienna nie jest istotna dla modelu i można ją z niego usunąć. Na końcu otrzymujemy jeszcze kilka wartości oceniających dobrany model jako całość. Znajoma powinna być wartość R-squared. Przyjmuje ona wartości z zakresu od 0 do 1 i oznacza procent wariancji obecnej w danych jaka może być wyjaśniona przy pomocy danego modelu. Może być przydatna przy ocenie który z kilku modeli wybrać do opisu naszych danych. Wartość adjusted R squared uwzględnia również ilość zmiennych jakie podaliśmy w formule. 6.4.2 Zmienne jakościowe w modelu W modelu możemy uwzględniać również zmienne jakościowe, muszą one jednak zostać zakodowane - zmienione w dane liczbowe. Funkcja lm domyślnie uznaje pierwszy poziom zmiennej za referencyjny, kolejne poziomy bedą się do niego odnosić. # zbiór danych dotyczący wzrostu kurzcaków w zależności od rodzaju karmy chick &lt;- ChickWeight summary(lm(weight ~ Time + Diet, data = chick)) ## ## Call: ## lm(formula = weight ~ Time + Diet, data = chick) ## ## Residuals: ## Min 1Q Median 3Q Max ## -136.851 -17.151 -2.595 15.033 141.816 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.9244 3.3607 3.251 0.00122 ** ## Time 8.7505 0.2218 39.451 &lt; 2e-16 *** ## Diet2 16.1661 4.0858 3.957 8.56e-05 *** ## Diet3 36.4994 4.0858 8.933 &lt; 2e-16 *** ## Diet4 30.2335 4.1075 7.361 6.39e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 35.99 on 573 degrees of freedom ## Multiple R-squared: 0.7453, Adjusted R-squared: 0.7435 ## F-statistic: 419.2 on 4 and 573 DF, p-value: &lt; 2.2e-16 p &lt;- ggplot(chick, aes(x = Time, y = weight)) p + geom_point() + stat_smooth(aes(color = Diet), method = &quot;lm&quot;, se = FALSE, size = 1) ## `geom_smooth()` using formula &#39;y ~ x&#39; Wartości przy przy kolejnych typach karmy - Diet2, Diet3, Diet4, pokazują o ile średnio różnią się wartości wyznaczone dla nich od poziomu referencyjnego czyli Diet1. To znaczy, że kurczaki karmione karmą nr 2 są o 16.17 g cięższe od kurczaków karmionych karmą nr 1. 6.4.3 Pakiet drc - dose response models Pakiet drc zawiera szereg funkcji ułatwiających dopasowywanie do danych wiele modeli popularnych w biologii np. wzrost logistyczny, rozpad eksponencjalny, Michaelisa-Menten i inne. Podstawową funkcja to drm, w której podajemmy formułę, podobnie jak w funkcji lm oraz koniecznie funkcję startową, która ma zostać użyta do poszukiwania modelu. Funkcje o kolejnych numerach różnią się ilością parametrów, które są uznawane za stałe np. MM.2 zakłada że przy x = 0, y też jest równe 0. Model Funkcja startowa Logistyczny LL.2, LL.3, LL.4, LL.5 Michaelisa-Menten MM.2, MM.3 Eksponencjalny EXD.2, EXD.3 Wykres razem z dopasowaniem można uzyskać dzięki standardowej funkcji plot. Można również porównać kilka modeli podając wektor ze zmienną dzielącą dane na poziomy. library(drc) ## ## &#39;drc&#39; has been loaded. ## Please cite R and &#39;drc&#39; if used for a publication, ## for references type &#39;citation()&#39; and &#39;citation(&#39;drc&#39;)&#39;. ## ## Attaching package: &#39;drc&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## gaussian, getInitial # przykładowe dane dane &lt;- data.frame(stezenie = c( 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1, 1.5), predkosc = c( 0.3, 0.5, 0.8, 0.9, 1, 1.02, 1.09, 1.15, 1.23)) model &lt;- drm(predkosc~stezenie, data = dane, fct = MM.2()) # d to prędkośc maksymalna, e to Km # w podsumowaniu dostajemy błąd standardowy i wartość p summary(model) ## ## Model fitted: Michaelis-Menten (2 parms) ## ## Parameter estimates: ## ## Estimate Std. Error t-value p-value ## d:(Intercept) 1.540562 0.082354 18.7066 3.098e-07 *** ## e:(Intercept) 0.321284 0.047915 6.7053 0.0002761 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: ## ## 0.05833157 (7 degrees of freedom) plot(model, log=&quot;&quot;) # przykładowe dane do porównania np. dwóch enzymów dane1 &lt;- dane dane1$predkosc &lt;- dane1$predkosc/2 dane &lt;- rbind(dane, dane1) dane$poziom &lt;- rep(c(&quot;A&quot;, &quot;B&quot;), each = 9) # model z dodanym podziałem na poziomy, możemy też nazwać oznaczane parametry model &lt;- drm(predkosc~stezenie, poziom, data = dane, fct = MM.2(names = c(d = &quot;Vmax&quot;, e = &quot;Km&quot;))) summary(model) ## ## Model fitted: Michaelis-Menten (2 parms) ## ## Parameter estimates: ## ## Estimate Std. Error t-value p-value ## Vmax:A 1.540560 0.065106 23.6622 1.089e-12 *** ## Vmax:B 0.770280 0.065106 11.8311 1.122e-08 *** ## Km:A 0.321282 0.037880 8.4816 6.889e-07 *** ## Km:B 0.321282 0.075759 4.2408 0.0008227 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: ## ## 0.04611515 (14 degrees of freedom) plot(model, log=&quot;&quot;) # Podobnie wygląda dopasowywanie funkcji logistycznej # Korzystamy z przykładowych danych z pakietu drc dla wpływu herbicydów na tylakoidy spinach.m1 &lt;- drm(SLOPE~DOSE, CURVE, data = spinach, fct = LL.4()) summary(spinach.m1) ## ## Model fitted: Log-logistic (ED50 as parameter) (4 parms) ## ## Parameter estimates: ## ## Estimate Std. Error t-value p-value ## b:1 0.5195192 0.0763600 6.8036 1.347e-09 *** ## b:2 0.8007959 0.2256794 3.5484 0.0006340 *** ## b:3 0.6819134 0.1285568 5.3044 8.838e-07 *** ## b:4 1.8448094 0.1663521 11.0898 &lt; 2.2e-16 *** ## b:5 1.6507576 0.1758293 9.3884 8.857e-15 *** ## c:1 -0.0165952 0.1078254 -0.1539 0.8780472 ## c:2 0.1325890 0.0471932 2.8095 0.0061561 ** ## c:3 0.1464061 0.0604288 2.4228 0.0175253 * ## c:4 0.0795516 0.0394596 2.0160 0.0469555 * ## c:5 -0.0090656 0.0443536 -0.2044 0.8385337 ## d:1 1.8795534 0.0423710 44.3594 &lt; 2.2e-16 *** ## d:2 0.9460003 0.0422667 22.3817 &lt; 2.2e-16 *** ## d:3 1.0903215 0.0405604 26.8814 &lt; 2.2e-16 *** ## d:4 2.1535780 0.0281853 76.4079 &lt; 2.2e-16 *** ## d:5 1.8062825 0.0292460 61.7616 &lt; 2.2e-16 *** ## e:1 1.7949548 0.4782321 3.7533 0.0003183 *** ## e:2 0.9455299 0.2494933 3.7898 0.0002809 *** ## e:3 1.3730228 0.4526848 3.0331 0.0032100 ** ## e:4 0.1973263 0.0101895 19.3657 &lt; 2.2e-16 *** ## e:5 0.2107935 0.0138248 15.2475 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: ## ## 0.0735284 (85 degrees of freedom) plot(spinach.m1) Możliwości tego pakietu sa dużo większe niż przedstawione powyżej. Autorzy przygotowali bardzo dobrą instrukcję użytkowania swojego pakietu razem ze szczegółowymi przykładami użycia wszystkich funkcji. Można ją znaleźć na stronie Biossay. 6.5 Analiza ANOVA Test ANOVA zakłada, że nasze dane pochodzą z rozkładu normalnego, mają takie same wariancje i są niezależne. Jeżeli nasze dane nie spełniają wymogu normalności można albo dane znormalizować (np logarytm) albo zastosować test nieparametryczny np. test Kruskala_Wallisa albo test Friedmana. Analizę wariancji można podzielić na jedno- i wieloczynnikową. Dane powinny zawierać wektor wartości (ilościowy), które można pogrupować wobec jednej lub więcej zmiennych jakościowych. ANOVA w R można przeprowadzić na kilka sposobów, do popularnych należą funkcje anova i aov, które różnią się sposobem wywołania i prezentacji wyników. Aby stwierdzić które średnie w naszym zbiorze danych różnią się można przeprowadzić tzw. testy post hoc np. test HSD Tukeya - TukeyHSD, HSD.test (pakiet agricolae). # przykładowe dane z rozkładu normalnego, różniące się średnią dane &lt;- data.frame(x = c(rnorm(200,1), rnorm(200,1.3), rnorm(200, 1)), y = rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;), each = 200)) # ANOVA przy pomocy funkcji aov, konieczne użycie summary dla wyświetlenia wyniku model2 &lt;- aov(x~y, data = dane) summary(model2) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## y 2 21.4 10.721 10.47 3.38e-05 *** ## Residuals 597 611.0 1.023 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # test Tukeya # Otrzymujemy wartość p dla każdej pary czynników i różnicę z przedziałem ufności TukeyHSD(model2) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = x ~ y, data = dane) ## ## $y ## diff lwr upr p adj ## B-A 0.3082657 0.07056901 0.54596248 0.0068072 ## C-A -0.1451069 -0.38280364 0.09258983 0.3238938 ## C-B -0.4533726 -0.69106938 -0.21567591 0.0000264 # wynik testu Tukeya można pokazać na wykresie plot(TukeyHSD(model2)) # Analiza dwuczynnikowa # Dodajemy nową kolumnę do danych zawierającą losowy czynnik z - nie powinien wpływać na średnią dane &lt;- data.frame(dane, z = sample(c(&quot;d&quot;, &quot;e&quot;, &quot;f&quot;), 600, replace = T)) model3 &lt;- aov(lm(x~y + z, data = dane)) summary(model3) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## y 2 21.4 10.721 10.472 3.39e-05 *** ## z 2 1.9 0.939 0.917 0.4 ## Residuals 595 609.1 1.024 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 TukeyHSD(model3) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = lm(x ~ y + z, data = dane)) ## ## $y ## diff lwr upr p adj ## B-A 0.3082657 0.07053406 0.54599743 0.0068173 ## C-A -0.1451069 -0.38283858 0.09262478 0.3239967 ## C-B -0.4533726 -0.69110433 -0.21564097 0.0000265 ## ## $z ## diff lwr upr p adj ## e-d -0.13293759 -0.3733960 0.1075208 0.3962997 ## f-d -0.02981066 -0.2634909 0.2038696 0.9516867 ## f-e 0.10312693 -0.1367823 0.3430362 0.5708251 # z analizą interakcji między y i z model4 &lt;- aov(lm(x~y + z + y:z, data = dane)) summary(model4) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## y 2 21.4 10.721 10.416 3.58e-05 *** ## z 2 1.9 0.939 0.912 0.402 ## y:z 4 0.8 0.201 0.196 0.941 ## Residuals 591 608.3 1.029 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 TukeyHSD(model4) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = lm(x ~ y + z + y:z, data = dane)) ## ## $y ## diff lwr upr p adj ## B-A 0.3082657 0.06988454 0.5466470 0.0070013 ## C-A -0.1451069 -0.38348811 0.0932743 0.3259704 ## C-B -0.4533726 -0.69175385 -0.2149914 0.0000281 ## ## $z ## diff lwr upr p adj ## e-d -0.13293759 -0.3740530 0.1081778 0.3982824 ## f-d -0.02981066 -0.2641293 0.2045080 0.9519415 ## f-e 0.10312693 -0.1374378 0.3436917 0.5725553 ## ## $`y:z` ## diff lwr upr p adj ## B:d-A:d 0.29169835 -0.23720856 0.820605261 0.7359430 ## C:d-A:d -0.24652931 -0.79887024 0.305811617 0.9016398 ## A:e-A:d -0.17273824 -0.73220104 0.386724559 0.9890591 ## B:e-A:d 0.09317859 -0.45691785 0.643275023 0.9998503 ## C:e-A:d -0.26587624 -0.82052453 0.288772062 0.8590070 ## A:f-A:d -0.10214693 -0.63626789 0.431974033 0.9996283 ## B:f-A:d 0.26382737 -0.29319391 0.820848659 0.8670527 ## C:f-A:d -0.19632774 -0.72523465 0.332579172 0.9651189 ## C:d-B:d -0.53822766 -1.07803023 0.001574904 0.0513479 ## A:e-B:d -0.46443659 -1.01152427 0.082651091 0.1712732 ## B:e-B:d -0.19851977 -0.73602549 0.338985955 0.9661548 ## C:e-B:d -0.55757459 -1.09973789 -0.015411287 0.0383710 ## A:f-B:d -0.39384528 -0.91498971 0.127299145 0.3123801 ## B:f-B:d -0.02787098 -0.57246167 0.516719714 1.0000000 ## C:f-B:d -0.48802609 -1.00382530 0.027773125 0.0802806 ## A:e-C:d 0.07379107 -0.49598337 0.643565517 0.9999808 ## B:e-C:d 0.33970790 -0.22087250 0.900288297 0.6232939 ## C:e-C:d -0.01934692 -0.58439473 0.545700887 1.0000000 ## A:f-C:d 0.14438238 -0.40052999 0.689294758 0.9961077 ## B:f-C:d 0.51035669 -0.05702062 1.077733991 0.1173507 ## C:f-C:d 0.05020158 -0.48960099 0.590004144 0.9999986 ## B:e-A:e 0.26591682 -0.30168207 0.833515718 0.8740549 ## C:e-A:e -0.09313800 -0.66514949 0.478873496 0.9998889 ## A:f-A:e 0.07059131 -0.48153876 0.622721382 0.9999826 ## B:f-A:e 0.43656561 -0.13774713 1.010878355 0.3044797 ## C:f-A:e -0.02358950 -0.57067718 0.523498185 1.0000000 ## C:e-B:e -0.35905482 -0.92190881 0.203799170 0.5537669 ## A:f-B:e -0.19532552 -0.73796267 0.347311642 0.9710370 ## B:f-B:e 0.17064879 -0.39454374 0.735841316 0.9905600 ## C:f-B:e -0.28950632 -0.82701204 0.247999398 0.7605828 ## A:f-C:e 0.16372931 -0.38352176 0.710980372 0.9911155 ## B:f-C:e 0.52970361 -0.03992016 1.099327379 0.0919220 ## C:f-C:e 0.06954850 -0.47261480 0.611711800 0.9999822 ## B:f-A:f 0.36597430 -0.18368169 0.915630292 0.4929824 ## C:f-A:f -0.09418081 -0.61532523 0.426963619 0.9997563 ## C:f-B:f -0.46015511 -1.00474580 0.084435582 0.1761651 # test nieparametryczny Kruskala-Wallisa z pakietu podstawowego wynik &lt;- kruskal.test(dane$x,dane$y) wynik ## ## Kruskal-Wallis rank sum test ## ## data: dane$x and dane$y ## Kruskal-Wallis chi-squared = 18.758, df = 2, p-value = 8.448e-05 # albo z pakietu agricolae - pokazuje nie tylko czy coś się różni, ale również które grupy wynik &lt;- agricolae::kruskal(dane$x,dane$y) wynik ## $statistics ## Chisq Df p.chisq t.value MSD ## 18.75789 2 8.448412e-05 1.963946 33.56365 ## ## $parameters ## test p.ajusted name.t ntr alpha ## Kruskal-Wallis none dane$y 3 0.05 ## ## $means ## dane.x rank std r Min Max Q25 Q50 ## A 1.0811121 291.955 1.0485256 200 -2.0832352 3.923038 0.4085795 1.1321930 ## B 1.3893779 341.575 0.9788305 200 -0.9459343 3.808629 0.7090154 1.3669592 ## C 0.9360052 267.970 1.0064069 200 -1.5606246 3.654266 0.2692844 0.8887481 ## Q75 ## A 1.611796 ## B 1.988996 ## C 1.655163 ## ## $comparison ## NULL ## ## $groups ## dane$x groups ## B 341.575 a ## A 291.955 b ## C 267.970 b ## ## attr(,&quot;class&quot;) ## [1] &quot;group&quot; "],["miscellaneous.html", "Chapter 7 Miscellaneous", " Chapter 7 Miscellaneous Pakiet beepr pozwala na generowanie dźwięków - funkcja beep :) Dostępnych jest 10 różnych, można również podać własny plik .wav. Może się przydać jeżeli uruchamiamy w R jakiś dłuższy proces i chcemy wiedzieć kiedy się skończy. Pakiet fortunes zawiera zbiór cytatów na temat R, funkcja fortune Cytowanie R - dla całego R - wpisujemy citation(), dla poszczególnych pakietów citation(\"nazwa_pakietu\"), podaje też cytowanie w formacie latex. citation() ## ## To cite R in publications use: ## ## R Core Team (2021). R: A language and environment for statistical ## computing. R Foundation for Statistical Computing, Vienna, Austria. ## URL https://www.R-project.org/. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {R: A Language and Environment for Statistical Computing}, ## author = {{R Core Team}}, ## organization = {R Foundation for Statistical Computing}, ## address = {Vienna, Austria}, ## year = {2021}, ## url = {https://www.R-project.org/}, ## } ## ## We have invested a lot of time and effort in creating R, please cite it ## when using it for data analysis. See also &#39;citation(&quot;pkgname&quot;)&#39; for ## citing R packages. citation(&#39;ggplot2&#39;) ## ## To cite ggplot2 in publications, please use: ## ## H. Wickham. ggplot2: Elegant Graphics for Data Analysis. ## Springer-Verlag New York, 2016. ## ## A BibTeX entry for LaTeX users is ## ## @Book{, ## author = {Hadley Wickham}, ## title = {ggplot2: Elegant Graphics for Data Analysis}, ## publisher = {Springer-Verlag New York}, ## year = {2016}, ## isbn = {978-3-319-24277-4}, ## url = {https://ggplot2.tidyverse.org}, ## } "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
